
1. [[#Введение|Введение]] 18.1
2. [[#Задачи и thread|Задачи и thread]] 18.2
	1. [[#Передача аргументов|Передача аргументов]] 18.2.1
	2. [[#Возвращение результатов|Возвращение результатов]] 18.2.2
3. [[#Обмен данными|Обмен данными]] 18.3
	1. [[#mutex и блокировки|mutex и блокировки]] 18.3.1
	2. [[#atomic|atomic]] 18.3.2
4. [[#Ожидание событий|Ожидание событий]] 18.4
5. [[#Коммуникации задач|Коммуникации задач]] 18.5
	1. [[#future и promise|future и promise]] 18.5.1


# Введение

***===Параллелизм===*** – выполнение нескольких задач одновременно – широко используется для повышения пропускной способности (за счет использования нескольких процессоров для одного вычисления) или для повышения быстродействия (позволяя одной части программы выполнять работу, в то время как другая ожидает ответа). Все современные языки программирования обеспечивают поддержку этого. Поддержка, предоставляемая стандартной библиотекой C++, является переносимым и типобезопасным вариантом того, что используется в C++ уже более 20 лет и почти повсеместно поддерживается современным оборудованием. Поддержка стандартной библиотеки в первую очередь направлена на поддержку параллелизма на системном уровне, а не на прямое предоставление сложных моделей параллелизма более высокого уровня; они могут поставляться в виде библиотек, созданных с использованием средств стандартной библиотеки.

Стандартная библиотека напрямую поддерживает одновременное выполнение нескольких потоков в одном адресном пространстве. Чтобы обеспечить это, C++ предоставляет подходящую модель памяти и набор атомарных операций. Атомарные операции позволяют программировать без блокировок. Модель памяти гарантирует, что до тех пор, пока программист избегает состояния гонки за данные (неконтролируемый параллельный доступ к изменяемым данным), все работает так, как можно было бы наивно ожидать. Однако большинство пользователей увидят параллелизм только в терминах стандартной библиотеки и библиотек, построенных поверх нее. В этом разделе кратко приведены примеры основных средств поддержки параллелизма стандартной библиотеки: [[thread|thread]], [[mutex|mutex]], операции [[lock|lock()]], [[packaged_task|packaged_task]] и [[future|future]]. Эти функции основаны непосредственно на том, что предлагают операционные системы, и не приводят к снижению производительности по сравнению с ними. Они также не гарантируют значительного повышения производительности по сравнению с тем, что предлагает операционная система.

Не рассматривайте параллелизм как панацею. Если задачу можно выполнять последовательно, то часто это делается проще и быстрее. Передача информации из одного потока в другой может оказаться на удивление дорогостоящей.

В качестве альтернативы использованию явных функций параллелизма мы часто можем использовать [[Алгоритмы - STL#Параллельные алгоритмы|параллельный алгоритм]] для использования [[Числовые вычисления#Многопоточные численные алгоритмы|нескольких механизмов выполнения для повышения производительности]].

Наконец, C++ поддерживает [[Особенности сопрограмм|корутины (сопрограммы)]], то есть функции, которые сохраняют свое состояние между вызовами.

# Задачи и thread

Мы называем вычисление, которое потенциально может выполняться одновременно с другими вычислениями, [[task|задачей (task)]]. [[thread|Поток (thread)]]- это представление задачи в программе на системном уровне. Задача, которая должна выполняться одновременно с другими задачами, запускается путем создания [[thread|thread]] (находящегося в `<thread>`) с задачей в качестве аргумента. Задача - это функция или функциональный объект:
```c++
void f();               // function

struct F {              // function object
	void operator()();  // F's call operator
};

void user()
{
	thread t1 {f};      // f() executes in separate thread
	thread t2 {F{}};    // F{}() executes in separate thread

	t1.join();          // wait for t1
	t2.join();          // wait for t2
}
```

Функции `join()` гарантируют, что мы не выйдем из `user()` до завершения потоков. “Присоединиться” к потоку означает “дождаться завершения потока”.

Легко забыть `join()`, и результаты этого обычно плохие, поэтому стандартная библиотека предоставляет [[thread#std jthread|jthread]], который является “присоединённым thread”, который следует `RAII` вызывая [[thread#Функции join и detach|join()]] с помощью своего деструктора:
```c++
void user()
{
	jthread t1 {f};    // f() executes in separate thread
	jthread t2 {F{}};  // F{}() executes in separate thread
}
```

Присоединение к потоку выполняется деструкторами, поэтому порядок построения обратный. Здесь мы ждем завершения `t2` до `t1`.

Потоки программы совместно используют одно адресное пространство. В этом потоки отличаются от процессов, которые обычно напрямую не обмениваются данными. Поскольку потоки совместно используют адресное пространство, они могут взаимодействовать через общие объекты ( #§18_3). Такая связь обычно контролируется блокировками или другими механизмами для предотвращения состояние гонки за данные (неконтролируемый параллельный доступ к переменной).

Программирование параллельных задач может быть очень сложным делом. Рассмотрим возможные реализации задач `f` (функция) и `F` (функциональный объект):
```c++
void f()
{
	cout << "Hello ";
}

struct F {
	void operator()() { cout << "Parallel World!\n"; }
};
```

Это пример серьезной ошибки: здесь и `f`, и `F{}` используют объект `cout` без какой-либо формы синхронизации. Результирующий вывод был бы непредсказуемым и мог бы варьироваться при различных выполнениях программы, поскольку порядок выполнения отдельных операций в двух задачах не определен. Программа может выдавать “странный” вывод, например
```
PaHerallllel o World!
```

Только определённая в стандарте гарантия спасает нас от гонки данных в рамках определения [[stream#std ostream|ostream]], которая может привести к сбою.

Чтобы избежать подобных проблем с выходными потоками, либо попросите только один [[thread|thread]] использовать выходной поток, либо используйте [[syncstream#osyncstream|osyncstream]].

При определении задач многопоточной программы наша цель состоит в том, чтобы полностью разделить задачи, за исключением случаев, когда они взаимодействуют простыми и очевидными способами. Самый простой способ представить параллельную задачу как функцию, которая выполняется одновременно с вызывающей ее. Чтобы это сработало, нам просто нужно передать аргументы, вернуть результат и убедиться, что между ними нет использования общих данных (никаких соревнований за данные).

## Передача аргументов

Как правило, для работы задачи требуются данные. Мы можем легко передавать данные (или указатели, или ссылки на данные) в качестве аргументов. Рассмотрим:
```c++
void f(vector<double>& v);   // function: do something with v

struct F {                   // function object: do something with v
	vector<double>& v;
	F(vector<double>& vv) :v{vv} { }
	void operator()();       // application operator
};

int main()
{
	vector<double> some_vec {1, 2, 3, 4, 5, 6, 7, 8, 9};
	vector<double> vec2 {10, 11, 12, 13, 14};

	// f(some_vec) executes in a separate thread
	jthread t1 {f, ref(some_vec)};
	// F(vec2)() executes in a separate thread	
	jthread t2 {F{vec2}};
}
```

`F{vec2}` принимает ссылку на вектор в качестве аргумента в `F`. Теперь `F` может использовать этот вектор, и, надеюсь, никакая другая задача не обращается к `vec2` во время выполнения `F`. Передача `vec2` по значению устранила бы этот риск.

Инициализация с помощью `{f, ref(some_vec)}` использует конструктор вариадик шаблона [[thread|thread]], который может принимать [[Концепты и обобщенное программирование - STL#Шаблоны с переменным числом аргументов|произвольную последовательность аргументов]]. `ref()` - это функция типа из `<functional>`, которая, к сожалению, необходима для указания [[Вариативные шаблоны#Вариативные шаблоны|вариадик шаблону]] обрабатывать `some_vec` как ссылку, а не как объект. Без `ref()` аргумент `some_vec` передавался бы по значению. Компилятор проверяет, что первый аргумент может быть вызван с учетом следующих аргументов, и создает необходимый объект функции для передачи потоку. Таким образом, если `F::operator()()` и `f()` выполняют один и тот же алгоритм, то обработка двух задач примерно эквивалентна: в обоих случаях создается функциональный объект для запуска [[thread|thread]].

# Возвращение результатов

[[Параллелизм-stl#Передача аргументов|В примере]], я передаю аргументы по [[По значению или по ссылке#Передача с помощью неконстантной ссылки|неконстантной ссылке]]. Я делаю это только в том случае, если ожидаю, что [[Программы - STL#Указатели, Массивы и Ссылки|задача изменит значение упомянутых данных]]. Это несколько хитрый, но нередкий способ вернуть результат. Более явный метод заключается в передаче входных данных по [[const|const]] ссылке и передаче указателя или ссылки на местоположение результата в качестве отдельного аргумента:
```c++
// take input from v; place result in *res
void f(const vector<double>& v, double* res);

class F {
	public:
		F(const vector<double>& vv, double* p) :v{vv}, res{p} { }
		void operator()();        // place result in *res
	
	private:
		const vector<double>& v;  // source of input
		double* res;              // target for output
};

double g(const vector<double>&);  // use return value

void user(vector<double>& vec1, vector<double> vec2, vector<double> vec3)
{
	double res1;
	double res2;
	double res3;

	// f(vec1,&res1) executes in a separate thread
	thread t1 {f,cref(vec1),&res1}; 
	// F{vec2,&res2}() executes in a separate thread
	thread t2 {F{vec2,&res2}};
	// capture local variables by reference
	thread t3 { [&](){ res3 = g(vec3); } };

	t1.join();
	t2.join();
	t3.join();
	
	// join before using results
	cout << res1 << ' ' << res2 << ' ' << res3 << '\n';
}
```

Здесь `cref(vec1)` передает [[const|const]] ссылку на `vec1` в качестве аргумента для `t1`.

Это работает, и техника очень распространена, но я не считаю возврат результатов через ссылки особенно элегантным, поэтому я возвращаюсь к этой теме в #§18_5_1.

# Обмен данными

Иногда задачам требуется обмениваться данными. В этом случае доступ должен быть синхронизирован таким образом, чтобы одновременно имела доступ не более чем одна задача. Опытные программисты воспримут это как упрощение (например, нет проблем с одновременным чтением многими задачами неизменяемых данных), но подумайте, как обеспечить, чтобы не более чем одна задача одновременно имела доступ к заданному набору объектов.

## mutex и блокировки

[[mutex|mutex]], “объект взаимного исключения”, является ключевым элементом общего обмена данными между [[thread|thread]]. [[thread|thread]] получает [[mutex|mutex]] с помощью операции [[mutex#Захват мьютексов в различном порядке|lock()]]:
```c++
mutex m;                   // controlling mutex
int sh;                    // shared data

void f()
{
	scoped_lock lck {m};   // acquire mutex
	sh += 7;               // manipulate shared data
}
						   // release mutex implicitly
```

Тип `lck` выводится как [[lock#Тип std scoped_lock|scoped_lock<mutex>]]. Конструктор [[lock#Тип std scoped_lock|scoped_lock]] получает мьютекс (посредством вызова `m.lock()`). Если другой поток уже получил мьютекс, поток ожидает (“блокируется”) до тех пор, пока другой поток не завершит свой доступ. Как только поток завершает свой доступ к общим данным, [[lock#Тип std scoped_lock|scoped_lock]] освобождает [[mutex|mutex]] (вызовом `m.unlock()`). Когда [[mutex|mutex]] освобождается, [[thread|thread]], ожидающие его, возобновляют выполнение (“пробуждаются”). Средства взаимного исключения и блокировки находятся в `<mutex>`.

Обратите внимание на [[Основные операции#Управление ресурсами|использование RAII]]. Использование дескрипторов ресурсов, таких как [[lock#Тип std scoped_lock|scoped_lock]] и [[lock#Тип std unique_lock|unique_lock]], проще и намного безопаснее, чем явная блокировка и разблокировка [[mutex|mutex]].

Соответствие между общими данными и [[mutex|mutex]] зависит от соглашения: программист должен знать, какой [[mutex|mutex]] должен соответствовать каким данным. Очевидно, что это чревато ошибками, и столь же очевидно, что мы стараемся сделать соответствие понятным с помощью различных языковых средств. Например:
```c++
class Record {
	public:
		mutex rm;
	// ...
};
```

Не нужно быть гением, чтобы догадаться, что для `Record` с именем `rec` вы должны захватить `rec.rm`, прежде чем получить доступ к остальной части `rec`, хотя комментарий или более подходящее название могли бы помочь читателю.

Нередки случаи, когда для выполнения какого-либо действия требуется одновременный доступ к нескольким ресурсам. Это может привести к тупиковой ситуации. Например, если `thread1` получает `mutex1`, а затем пытается получить `mutex2`, в то время как `thread2` получает `mutex2`, а затем пытается получить `mutex1`, то ни одна из задач никогда не будет продолжена дальше. [[lock#Тип std scoped_lock|scoped_lock]] помогает, позволяя нам получать несколько блокировок одновременно:
```c++
void f()
{
	scoped_lock lck {mutex1,mutex2,mutex3}; // acquire all three locks
	// ... manipulate shared data ...
} // implicitly release all mutexes
```

Этот [[lock#Тип std scoped_lock|scoped_lock]] будет запущен только после получения всех его аргументов [[mutex|mutex]] и никогда не будет блокироваться (“переходить в спящий режим”) при удержании [[mutex|mutex]]. Деструктор для [[lock#Тип std scoped_lock|scoped_lock]] гарантирует, что [[mutex|mutex]] будут освобождены, когда [[thread|thread]] покинет область видимости.

Обмен информацией через совместно используемые данные – довольно низкоуровневое средство. В частности, программист должен разработать способы узнать, какая задача была выполнена, а какая нет в рамках различных задач. В этом отношении использование общих данных уступает понятию вызова и возврата. С другой стороны, некоторые люди убеждены, что совместное использование должно быть более эффективным, чем копирование аргументов и возвращаемых данных. Это действительно может быть так, когда речь идет о больших объемах данных, но блокировка и разблокировка являются относительно дорогостоящими операциями. Кроме того, современные машины очень хорошо копируют данные, особенно компактные, такие как элементы [[vector|vector]]. Поэтому не выбирайте общие данные для обмена информацией бездумно, из-за “эффективности” и, желательно, проводите измерения быстродействия.

Базовый [[mutex|mutex]] позволяет одному потоку одновременно получать доступ к данным. Один из наиболее распространенных способов обмена данными - это обмен между многими читающими и одним пишущим потоком. Эта идиома ”блокировка читающий-пишущий" поддерживается [[mutex#std shared_mutex|shared_mutex]]. Читающий поток получит мьютекс `“shared”`, чтобы другие читающие все еще могли получить доступ, в то время как пишущий поток будет требовать эксклюзивного доступа. Например:
```c++
shared_mutex mx;          // a mutex that can be shared

void reader()
{
	shared_lock lck {mx}; // willing to share access with other readers
						  // ... read ...
}

void writer()
{
	unique_lock lck {mx}; // needs exclusive (unique) access
						  // ... write ...
}
```

## atomic

[[mutex|mutex]] - это довольно тяжелый механизм, задействующий операционную систему. Он позволяет выполнять произвольные объемы работы без состояний гонки за данные. Однако существует гораздо более простой и дешевый механизм для выполнения лишь небольшого объема работы: [[atomic|atomic переменная]]. Например, вот простой вариант классической блокировки с двойной проверкой:
```c++
mutex mut;
atomic<bool> init_x;   // initially false.
X x;                   // variable that requires nontrivial initialization

if (!init_x) {
	lock_guard lck {mut};
	if (!init_x) {
		// ... do nontrivial initialization of x ...
		init_x = true;
	}
}

// ... use x ...
```

[[atomic|atomic]] избавляет нас от большинства вариантов использования гораздо более дорогого [[mutex|mutex]]. Если бы `init_x` не был [[atomic|atomic]], эта инициализация завершалась бы неудачей очень редко, вызывая загадочные и трудновыявляемые ошибки, потому что происходило бы соревнование за данные в `init_x`.

Здесь я использовал [[lock#Тип std lock_guard|lock_guard]], а не [[lock#Тип std scoped_lock|scoped_lock]], потому что мне нужен был только один [[mutex|mutex]], поэтому было достаточно простейшей блокировки ([[lock#Тип std lock_guard|lock_guard]]).

# Ожидание событий

Иногда [[thread|thread]] необходимо дождаться какого-либо внешнего события, например, завершения другим [[thread|thread]] задачи или истечения определенного промежутка времени. Самое простое “событие” - это просто течение времени. Используя средства для работы времени, найденные в `<chrono>`, я могу написать:
```c++
using namespace chrono;

auto t0 = high_resolution_clock::now();
this_thread::sleep_for(milliseconds{20});

auto t1 = high_resolution_clock::now();
cout << duration_cast<nanoseconds>(t1-t0).count() << " nanoseconds passed\n";
```

Мне даже не нужно было запускать [[thread|thread]]; по умолчанию `this_thread` может ссылаться на один-единственный поток.

Я использовал [[Chrono#std duration_cast|duration_cast]], чтобы настроить единицы измерения часов на нужные мне наносекунды.

Базовая поддержка обмена данными с использованием внешних событий обеспечивается [[condition_variable|condition_variable]], находящимся в `<condition_variable>`. `condition_variable` - это механизм, позволяющий одному [[thread|thread]] ожидать другой [[thread|thread]]. В частности, это позволяет [[thread|thread]] ожидать возникновения некоторого условия (часто называемого событием) в результате работы, выполняемой другими [[thread|thread]].

Использование [[condition_variable|condition_variable]] поддерживает множество форм элегантного и эффективного совместного использования, но может быть довольно сложным. Рассмотрим классический пример взаимодействия двух [[thread|thread]] путем передачи сообщений через [[queue|queue]]. Для простоты я объявляю [[queue|queue]] и механизм предотвращения условий соревнований в этой [[queue|queue]] глобальными для производителя и потребителя:
```c++
class Message {            // object to be communicated
	// ...
};

queue<Message> mqueue;     // the queue of messages
condition_variable mcond;  // the variable communicating events
mutex mmutex;              // for synchronizing access to mcond
```

Типы [[queue|queue]], [[condition_variable|condition_variable]] и [[mutex|mutex]] предоставляются стандартной библиотекой. `consumer()` читает и обрабатывает `Message`:
```c++
void consumer()
{
	while(true) {
		unique_lock lck {mmutex};   // acquire mmutex
		
		// release mmutex and wait; re-acquire mmutex upon wakeup
		// don't wake up unless mqueue is non-empty
		mcond.wait(lck,[] { return !mqueue.empty(); }); 
			
		auto m = mqueue.front();    // get the message
		mqueue.pop();
		lck.unlock();               // release mmutex
		// ... process m ...
	}
}
```

Здесь я явно защищаю операции с [[queue|queue]] и с [[condition_variable|condition_variable]] с помощью [[lock#Тип std unique_lock|unique_lock]] для [[mutex|mutex]]. Ожидание [[condition_variable|condition_variable]] освобождает его аргумент блокировки до тех пор, пока ожидание не закончится (чтобы очередь не была пустой), а затем повторно запрашивает его. Явная проверка условия, здесь `!mqueue.empty()`, защищает от пробуждения только для того, чтобы обнаружить, что какая-то другая задача “добралась туда первой”, так что условие больше не выполняется.

Я использовал [[lock#Тип std unique_lock|unique_lock]], а не [[lock#Тип std scoped_lock|scoped_lock]] по двум причинам:
>
> Нам нужно передать блокировку в `condition_variable wait()`. [[lock#Тип std scoped_lock|scoped_lock]]  нельзя переместить, а [[lock#Тип std unique_lock|unique_lock]] можно
> 
> Мы хотим разблокировать [[mutex|mutex]], защищающий переменную условия, перед обработкой сообщения. [[lock#Тип std unique_lock|unique_lock]] предлагает операции, такие как `lock()` и `unlock()`, для низкоуровневого управления синхронизацией.

С другой стороны, [[lock#Тип std unique_lock|unique_lock]] может обрабатывать только один [[mutex|mutex]].

Соответствующий `producer` выглядит следующим образом:
```c++
void producer()
{
	while(true) {
		Message m;
		// ... fill the message ...
		scoped_lock lck {mmutex};
		mqueue.push(m);
		mcond.notify_one();
	}
}
```

# Коммуникации задач

Стандартная библиотека предоставляет несколько возможностей, позволяющих программистам работать на концептуальном уровне задач (работа, которая потенциально может выполняться одновременно), а не непосредственно на более низком уровне потоков и блокировок:
>
> [[future|future]] и [[promise|promise]] для возврата значения из задачи, созданной в отдельном потоке
> 
> [[packaged_task|packaged_task]], помогающий запускать задачи и подключать механизмы для возврата результата
> 
> [[async|async()]] для запуска задачи способом, очень похожим на вызов функции

Эти объекты находятся в `<future>`.

## future и promise















