
[[#Потокобезопасная очередь|Потокобезопасная очередь]] 12.3
1. [[#Блокировка очереди целиком|Блокировка очереди целиком]] 12.3.1
2. [[#Раздельная блокировка концов очереди|Раздельная блокировка концов очереди]] 12.3.2
	1. [[#Некорректная реализация|Некорректная реализация]] 12.3.2.1
	2. [[#Простая реализация очереди|Простая реализация очереди]] 12.3.2.2
	3. [[#Очередь с фиктивным элементом|Очередь с фиктивным элементом]] 12.3.2.3
	4. [[#Окончательная реализация|Окончательная реализация]] 12.3.2.4
	5. [[#Ожидание значения из очереди|Ожидание значения из очереди]] 12.3.2.5

# Потокобезопасная очередь

Как и в предыдущем разделе, начнём с ответа на вопрос, что такое очередь. Стандартный адаптер контейнера [[queue|std::queue]], объявленный в заголовочном файле `<queue>`, воплощает принцип «первым пришёл – первым ушёл» (англ. FIFO – first in first out). В его интерфейсе четыре основные функции.

![[ParallelProg_249.png]]

Функция-член `push` вставляет элемент в конец очереди, функция `pop` удаляет элемент из её начала; функция `back` позволяет получить ссылку на последний элемент очереди, а функция `front` – на первый. Кроме того, есть ещё вспомогательные функции, возвращающие размер очереди и позволяющие сравнивать очереди между собой. Пример использования очереди показан ниже.

```c++
#include <queue>

...

std::queue<int> myQueue;
std::cout << myQueue.empty() << ‘\n’;              // true
std::cout << myQueue.size() << ‘\n’;               // 0

myQueue.push(1);
myQueue.push(2);
myQueue.push(3);

std::cout << myQueue.back() << ‘\n’;              // 3
std::cout << myQueue.front() << ‘\n’;             // 1

while (!myQueue.empty()){
	std::cout << myQueue.back() << “ “;
	std::cout << myQueue.front() << “ : “;
	myQueue.pop();
}                                                // 3 1 : 3 2 : 3 3

std::cout << myQueue.empty() << ‘\n’;            // true
std::cout << myQueue.size() << ‘\n’;             // 0
```

Первый вариант реализации потокобезопасной очереди весьма похож на рассмотренную выше реализацию потокобезопасного стека.

## Блокировка очереди целиком

Начнём с наиболее очевидной реализации. Объединим функции-члены `front` и `pop` в функцию `frontAndPop`. Функция `push` остаётся без изменений и добавляет элемент в конец очереди. Что же касается функции `back`, которая возвращает последний элемент очереди, она для очереди в общем случае не обязательна, и есть большие сомнения, нужно ли её вообще поддерживать в данном примере. Вот некоторые основания для этого.
3. Поддержка функции `back` налагает на программиста дополнительные обязательства, тогда как клиенты редко нуждаются в этой операции.
4. Комбинированная операция `backAndPush` должна была бы возвращать значение, которое было в очереди последним перед добавлением нового элемента в конец. Такая составная операция могла бы выглядеть многообещающе, но обладает двумя серьёзными недостатками. Во-первых, значение, бывшее в очереди последним, эта функция должна возвращать путём копирования, поскольку возврат по ссылке или указателю открыл бы дорогу гонке данных. Однако копирование может нанести удар по производительности. Во-вторых, конструктор копирования может выбросить исключение.
5. Наличие двух отдельных функций `back` и `push` делает возможной гонку данных. В самом деле, пусть клиентский код делает некоторые предположения, основываясь на значении последнего элемента. Тогда может возникнуть ситуация, подобная той, что наблюдалась бы при наличии отдельных операций `front` и `pop`. Здесь справедливы те же соображения, которые мы разобрали выше в связи с операциями `pop` и `top` для потокобезопасного стека. Хотя подобный способ использования очереди выглядит необычным и маловероятен на практике, лучше поступить осторожно и не оставить даже теоретической возможности для такой ошибки.

Реализация потокобезопасной очереди довольно проста и весьма похожа на реализацию стека. Код показан ниже.

**Потокобезопасная очередь с полной блокировкой:**
```c++
// concurrentQueueCoarseLocking.cpp

#include <future>
#include <limits>
#include <iostream>
#include <mutex>
#include <queue>
#include <stdexcept>
#include <utility>

template <typename T,
		template <typename, typename> class Cont = std::deque>
class ConcurrentQueue {
	public:
		void push(T val) {
			std::lock_guard<std::mutex> lockQueue(mutexQueue);
			myQueue.push(std::move(val));
		}

		T frontAndPop() {
			std::lock_guard<std::mutex> lockQueue(mutexQueue);
			
			if ( myQueue.empty() )
				throw std::out_of_range(“The queue is empty!”);
			
			auto val = myQueue.front();
			myQueue.pop();
			return val;
		}

		ConcurrentQueue() = default;
		ConcurrentQueue(const ConcurrentQueue&) = delete;
		ConcurrentQueue& operator= (const ConcurrentQueue&) = delete;

	private:
		mutable std::mutex mutexQueue;
		std::queue<T, Cont<T, std::allocator<T>>> myQueue;
};

int main() {
	ConcurrentQueue<int> conQueue;

	auto fut0 = std::async([&conQueue]{ conQueue.push(2011); });
	auto fut1 = std::async([&conQueue]{ conQueue.push(2014); });
	auto fut2 = std::async([&conQueue]{ conQueue.push(2017); });
	auto fut3 = std::async([&conQueue]{ return conQueue.frontAndPop(); });
	auto fut4 = std::async([&conQueue]{ return conQueue.frontAndPop(); });
	auto fut5 = std::async([&conQueue]{ return conQueue.frontAndPop(); });

	fut0.get(), fut1.get(), fut2.get();

	std::cout << fut3.get() << std::endl;
	std::cout << fut4.get() << std::endl;
	std::cout << fut5.get() << std::endl;
}
```

Без пространных пояснений покажем сразу результат запуска программы.

![[ParallelProg_250.png]]

Можно ли считать задачу полностью решённой? Нет, так как у представленной здесь реализации имеется потенциал для оптимизации.

## Раздельная блокировка концов очереди

В отличие от стека, где добавление и изъятие элементов выполняются с одного и того же конца контейнера, в случае очереди операции `push` и `pop` работают с разными его концами.

### Некорректная реализация

Вместо того чтобы брать блокировку на всю очередь посредством единого мьютекса, можно было бы попытаться использовать отдельные мьютексы для начала и конца очереди в надежде, что это уменьшит общее количество синхронизаций.

**Некорректная реализация очереди с раздельной блокировкой:**
```c++
template <typename T,
			template <typename, typename> class Cont = std::deque>
class ConcurrentQueue {
	public:
		void push(T val) {
			std::lock_guard<std::mutex> lockQueue(mutexBackQueue);
			myQueue.push(std::move(val));
		}
		
		T frontAndPop() {
			std::lock_guard<std::mutex> lockQueue(mutexFrontQueue);
			
			if (myQueue.empty())
				throw std::out_of_range(“The queue is empty!”);

			auto val = myQueue.front();
			myQueue.pop();
			
			return val;
		}

		ConcurrentQueue() = default;
		ConcurrentQueue(const ConcurrentQueue&) = delete;
		ConcurrentQueue& operator= (const ConcurrentQueue&) = delete;

	private:
		mutable std::mutex mutexFrontQueue;
		mutable std::mutex mutexBackQueue;
		std::queue<T, Cont<T, std::allocator<T>>> myQueue;
};
```

Эта реализация содержит ошибку, которая делает её полностью некорректной. Если очередь пуста, её начало и конец совпадают, и операции `push` и `pop` работают над одним и тем же элементом, что приводит к гонке данных. Добавление в очередь фиктивного элемента, который всегда разделяет начало и конец, могло бы решить проблему.

Потокобезопасную очередь с раздельной блокировкой начала и конца невозможно построить, основываясь на абстракциях, предоставляемых стандартным типом [[queue|std::queue]]. Следовательно, структуру данных, лежащую в основе очереди, придётся реализовать самостоятельно. Прежде всего разберём, как можно реализовать очередь, а затем заделаем её потокобезопасной.

### Простая реализация очереди

Самая очевидная структура данных, на основе которой удобно реализовать очередь, – это односвязный список. Односвязным называют список, в котором у каждого элемента есть указатель на следующий элемент, но не на предыдущий. Для управления списком нужны указатель `head` на первый элемент списка и указатель `tail` на последний1 (см. рисунок). Такой список легко превратить в очередь, если изымать элементы операцией `pop` из начала списка, а добавлять операцией `push` в конец. Для удаления первого элемента из списка достаточно продвинуть указатель `head` на один элемент вперёд. Эта операция также должна возвращать значение удаляемого элемента. Для добавления элемента в конец очереди нужно в бывшем последнем элементе проставить указатель на новый элемент и поставить указатель `tail` на этот новый элемент. Операции добавления и изъятия элемента должны также обрабатывать ситуацию, когда в очереди нет ни одного элемента. Код реализации представлен ниже.

![[ParallelProg_251.png]]

**Простая реализация очереди:**
```c++
// simpleQueue.cpp

#include <iostream>
#include <memory>
#include <utility>

template <typename T>
class Queue {
	private:
		struct Node {
			T data;
			std::unique_ptr<Node> next;
			Node(T data_): data(std::move(data_)){}
		};

		std::unique_ptr<Node> head;
		Node* tail;

	public:
		Queue(): tail(nullptr) {};
		
		std::unique_ptr<T> pop() {
			if (!head) 
				throw std::out_of_range(“The queue is empty!”);

			std::unique_ptr<T> res =
					std::make_unique<T>(std::move(head->data));

			std::unique_ptr<Node> oldHead = std::move(head);

			head = std::move(oldHead->next);

			if (!head) 
				tail = nullptr;

			return res;
		}

		void push(T val) {
			std::unique_ptr<Node> newNode =
					std::make_unique<Node>(Node(std::move(val)));

			Node* newTail = newNode.get();

			if (tail) 
				tail->next= std::move(newNode);
			else 
				head = std::move(newNode);

			tail = newTail;
		}

		Queue(const Queue& other) = delete;
		Queue& operator=(const Queue& other) = delete;
};

int main() {
	std::cout << std::endl;

	Queue<int> myQueue;
	myQueue.push(1998);
	myQueue.push(2003);
	
	std::cout << *myQueue.pop() << std::endl;
	std::cout << *myQueue.pop() << std::endl;

	myQueue.push(2011);
	myQueue.push(2014);

	std::cout << *myQueue.pop() << std::endl;

	myQueue.push(2017);
	myQueue.push(2020);

	std::cout << *myQueue.pop() << std::endl;
	std::cout << *myQueue.pop() << std::endl;
	std::cout << *myQueue.pop() << std::endl;
	std::cout << std::endl;
}
```

Для автоматического управления временем жизни элементов списка используется умный указатель [[unique_ptr|std::unique_ptr]]. Переменная-член `tail`, однако, имеет тип обычного указателя, так как узел, на который она указывает, уже имеет владельца. Функция-член `push` (строки `void push(T val) { ... }`) добавляет новый элемент в очередь. Для этого сперва создаётся новый объект типа `Node` (строка `std::unique_ptr<Node> newNode = std::make_unique<Node>(Node(std::move(val)));`). Ему предстоит стать последним элементом списка (строка `Node* newTail = newNode.get();`). Если в старом состоянии списка последний элемент существует (т. е. если список не пуст), то указатель на следующий элемент в этом бывшем последнем элементе ставится на новый элемент (строка `if (tail) tail->next= std::move(newNode);`). В противном случае список пуст – тогда новый элемент становится первым элементом списка (строка `else head = std::move(newNode);`). Наконец, указатель `tail` устанавливается на только что добавленный элемент (строка `tail = newTail;`).

Функция-член `pop` (строки `std::unique_ptr<T> pop() { ... }`) изымает из списка первый элемент и возвращает содержащиеся в нём данные. Если список пуст, функция бросает исключение (строка `if (!head) throw std::out_of_range(“The queue is empty!”);`). В строке `std::unique_ptr<T> res = std::make_unique<T>(std::move(head->data));` создаётся значение, которое функция должна будет вернуть, затем первый элемент списка перемещается в промежуточную переменную `oldHead` (строка `std::unique_ptr<Node> oldHead = std::move(head);`). Адрес `oldHead->next` становится новым первым элементом списка (строка `head = std::move(oldHead->next);`). Наконец, если список содержал единственный элемент, его изъятие делает список пустым – в этом случае нужно обнулить указатель `tail` (строка `if (!head) tail = nullptr;`). На следующем рисунке показан результат запуска программы.

![[ParallelProg_252.png]]

Может возникнуть вопрос, почему очередь реализована именно таким образом – ведь она обладает тем же недостатком, о котором говорилось ранее: если очередь содержит ровно один элемент, её первый и последний элементы `head` и `tail` совпадают. В этом случае перемежающиеся вызовы операций `pop` и `push` из разных потоков могут привести к гонке данных. Например, обращение к члену-переменной `tail->next` в строке `if (tail) tail->next= std::move(newNode);` может произойти одновременно с обращением к той же переменной через `oldHead->next` в строке `head = std::move(oldHead->next);`. В конечном счёте это означает, что для корректной работы списка всё равно нужен единый мьютекс, блокирующий весь список при каждой операции. Ответ на этот вопрос таков. Действительно, эту реализацию очереди нельзя сделать потокобезопасной с помощью двух независимых мьютексов, но она послужит основой для такой раздельной блокировки. Для этого понадобится небольшая хитрость: нужно отделить первый элемент списка от последнего.

### Очередь с фиктивным элементом

Хитрость состоит в том, чтобы держать в очереди лишний элемент. Благодаря ему конец очереди никогда не совпадает с её началом, поэтому одновременные обращения к указателю `head` и к члену `next` по указателю `tail` никогда не приводят к гонке данных. Конечно же, за это приходится платить усложнением реализации, поскольку фиктивный элемент нужно как-то обрабатывать.

**Простая очередь с фиктивным элементом:**
```c++
// simpleQueueWithDummy.cpp

#include <iostream>
#include <memory>
#include <utility>

template <typename T>
class Queue {
	private:
		struct Node {
			T data;
			std::unique_ptr<Node> next;
			Node(T data_): data(std::move(data_)) {}
		};

		std::unique_ptr<Node> head;
		Node* tail;

	public:
		Queue(): head(new Node(T{})), tail(head.get()) {};

		std::unique_ptr<T> pop() {
			if (head.get() == tail)
				throw std::out_of_range(“The queue is empty!”);

			std::unique_ptr<T> res =
				std::make_unique<T>(std::move(head->data));

			std::unique_ptr<Node> oldHead = std::move(head);
			head = std::move(oldHead->next);

			return res;
		}

		void push(T val) {
			std::unique_ptr<Node> dummyNode =
				std::make_unique<Node>(Node(T{}));

			Node* newTail = dummyNode.get();

			tail->next= std::move(dummyNode);
			tail->data = val;

			tail = newTail;
		}

		Queue(const Queue& other) = delete;
		Queue& operator=(const Queue& other) = delete;
};

int main() {
	std::cout << std::endl;

	Queue<int> myQueue;
	myQueue.push(1998);
	myQueue.push(2003);

	std::cout << *myQueue.pop() << std::endl;
	std::cout << *myQueue.pop() << std::endl;

	myQueue.push(2011);
	myQueue.push(2014);

	std::cout << *myQueue.pop() << std::endl;

	myQueue.push(2017);
	myQueue.push(2020);
	
	std::cout << *myQueue.pop() << std::endl;
	std::cout << *myQueue.pop() << std::endl;
	std::cout << *myQueue.pop() << std::endl;
	
	std::cout << std::endl;
}
```

Отличие этой реализации от предыдущей невелико. Во-первых, указатели `head` и `tail` изначально указывают на фиктивный элемент. Посмотрим внимательнее на функцию `pop`. В строке `if (head.get() == tail)` делается проверка, является ли очередь логически пустой, т. е. содержит ли она элементы, помимо фиктивного. Функция `push` претерпевает более серьёзные изменения. Первым делом в строке `std::unique_ptr<Node> dummyNode = std::make_unique<Node>(Node(T{}));` создаётся новый фиктивный элемент, на который затем будет установлен указатель `tail` (строки `Node* newTail = dummyNode.get();` и `tail = newTail;`). Элемент, который ранее был фиктивным, теперь начинает указывать на новый фиктивный элемент как на следующий (строка `tail->next= std::move(dummyNode);`) и получает себе новое значение `val` (строка `tail->data = val;`).

Как и следовало ожидать, запуск этой программы приводит к такому же результату, что и запуск предыдущей реализации, не содержавшей фиктивного элемента.

![[ParallelProg_253.png]]

На этом преобразование кода закончено. Важно иметь в виду, что в новой реализации функции `push` и `pop` работают почти исключительно над разными концами очереди. Это позволит нам в будущем использовать в них два разных мьютекса. Лишь одна операция – проверка на пустоту очереди в строке `if (head.get() == tail)` – требует обоих мьютексов. Это не так плохо, ведь эта критическая секция занимает мало времени.

Теперь, имея на руках все элементы головоломки, соберём их вместе и построим потокобезопасную очередь с раздельной блокировкой начала и конца.

### Окончательная реализация

Синхронизация этой очереди основана на двух мьютексах. Один мьютекс защищает доступ к первому элементу очереди, другой – к последнему. Ещё один важный вопрос: в каких местах лучше поставить их блокировку? Чтобы добиться наилучшей производительности, критические секции нужно сделать как можно короче. Функцию `pop` придётся защитить блокировкой целиком, однако в функции `push` защищать нужно только ту часть, где используется переменная `tail`. Остальные операции выполняются над локальными переменными и потому не нуждаются в синхронизации.

**Потокобезопасная очередь с раздельной блокировкой операций:**
```c++
// concurrentQueueFineLocking.cpp

#include <future>
#include <iostream>
#include <memory>
#include <mutex>
#include <utility>

template <typename T>
class ConcurrentQueue {
	private:
		struct Node {
			T data;
			std::unique_ptr<Node> next;
			
			Node(T data_): data(std::move(data_)) {}
		};

		std::unique_ptr<Node> head;
		Node* tail;

		std::mutex headMutex;
		std::mutex tailMutex;

	public:
		ConcurrentQueue (): head(new Node(T{})), tail(head.get()) {};

		std::unique_ptr<T> pop() {
			std::lock_guard<std::mutex> headLock(headMutex);
			{
				std::lock_guard<std::mutex> tailLock(tailMutex);
				
				if (head.get() == tail)
					throw std::out_of_range(“The queue is empty!”);
			}

			std::unique_ptr<T> res =
				std::make_unique<T>(std::move(head->data));

			std::unique_ptr<Node> oldHead = std::move(head);
			head = std::move(oldHead->next);

			return res;
		}

		void push(T val) {
			std::unique_ptr<Node> dummyNode =
				std::make_unique<Node>(Node(T{}));

			Node* newTail = dummyNode.get();

			std::lock_guard<std::mutex> tailLock(tailMutex);
			
			tail->next= std::move(dummyNode);
			tail->data = val;

			tail = newTail;
		}

		Queue(const Queue& other) = delete;
		Queue& operator=(const Queue& other) = delete;
};

int main() {
	std::cout << std::endl;

	ConcurrentQueue<int> conQueue;

	auto fut = std::async([&conQueue]{ conQueue.push(2011); });
	auto fut1 = std::async([&conQueue]{ conQueue.push(2014); });
	auto fut2 = std::async([&conQueue]{ conQueue.push(2017); });

	auto fut3 = std::async([&conQueue]{ return *conQueue.pop(); });
	auto fut4 = std::async([&conQueue]{ return *conQueue.pop(); });
	auto fut5 = std::async([&conQueue]{ return *conQueue.pop(); });

	fut.get(), fut1.get(), fut2.get();

	std::cout << fut3.get() << std::endl;
	std::cout << fut4.get() << std::endl;
	std::cout << fut5.get() << std::endl;

	std::cout << std::endl;
}
```

В первую очередь зададимся вопросом, потокобезопасна ли эта реализация. Класс `ConcurrentQueue` обладает только двумя функциями-членами. Два мьютекса защищают от одновременного доступа односвязный список, состоящий из объектов типа `Node`. Мьютекс `headMutex` отвечает за доступ к первому элементу списка, а мьютекс `tailMutex` – за доступ к последнему элементу. Единственная операция, которая работает с указателями `head` и `tail` одновременно, защищена обоими мьютексами. Следовательно, данный тип свободен от гонки данных.

Далее, следует избегать захвата более чем одного мьютекса, потому что это может привести к мёртвой блокировке, если мьютексы захватываются не всегда в одном порядке. Хотя функция `pop` захватывает сначала мьютекс `headMutex`, а затем мьютекс `tailMutex`, возможности для мёртвой блокировки здесь нет, потому что вторая функция-член захватывает только один мьютекс. Таким образом, представленная здесь структура данных полностью потокобезопасна. Программа работает, как и ожидалось, результат её запуска показан на рисунке.

![[ParallelProg_254.png]]

### Ожидание значения из очереди

Воспользовавшись переменной условия, можно сделать так, чтобы в случае пустой очереди функция `pop` ждала появления в ней элемента.

**Потокобезопасная очередь с ожиданием:**
```c++
// concurrentQueueFineLockingWithWaiting.cpp

#include <condition_variable>
#include <future>
#include <iostream>
#include <memory>
#include <mutex>
#include <utility>

template <typename T>
class Queue {
	private:
		struct Node {
			T data;
			std::unique_ptr<Node> next;
			Node(T data_): data(std::move(data_)) {}
		};

		std::unique_ptr<Node> head;
		Node* tail;
		std::mutex headMutex;
		std::mutex tailMutex;
		
		std::condition_variable condVar;
	
	public:
		Queue()
			: head(new Node(T{}))
			, tail(head.get())
		{};

		std::unique_ptr<T> pop() {
			std::lock_guard<std::mutex> headLock(headMutex);
			{
				std::unique_lock<std::mutex> tailLock(tailMutex);
				
				if (head.get() == tail)
					condVar.wait(tailLock);
			}

			std::unique_ptr<T> res =
					std::make_unique<T>(std::move(head->data));
			
			std::unique_ptr<Node> oldHead = std::move(head);

			head = std::move(oldHead->next);
			
			return res;
		}

		void push(T val) {
			std::unique_ptr<Node> dummyNode =
					std::make_unique<Node>(Node(T{}));

			Node* newTail = dummyNode.get();
			{
				std::unique_lock<std::mutex> tailLock(tailMutex);

				tail->next= std::move(dummyNode);
				tail->data = val;
				tail = newTail;
			}
			condVar.notify_one();
		}

		Queue(const Queue& other) = delete;
		Queue& operator=(const Queue& other) = delete;
};

int main() {
	std::cout << std::endl;

	Queue<int> conQueue;

	auto fut = std::async([&conQueue]{ conQueue.push(2011); });
	auto fut1 = std::async([&conQueue]{ conQueue.push(2014); });
	auto fut2 = std::async([&conQueue]{ conQueue.push(2017); });
	
	auto fut3 = std::async([&conQueue]{ return *conQueue.pop(); });
	auto fut4 = std::async([&conQueue]{ return *conQueue.pop(); });
	auto fut5 = std::async([&conQueue]{ return *conQueue.pop(); });
	
	fut.get(), fut1.get(), fut2.get();
	
	std::cout << fut3.get() << std::endl;
	std::cout << fut4.get() << std::endl;
	std::cout << fut5.get() << std::endl;
	
	std::cout << std::endl;
}
```

Изменения по сравнению с предыдущей программой минимальны. Функция `pop` в строке `condVar.wait(tailLock);` ждёт оповещения о том, что в очереди появился новый элемент. Переменной условия нужен блокировщик типа [[lock#Тип std unique_lock|std::unique_lock]] вмес­то использованного в предыдущей версии типа [[lock#Тип std lock_guard|std::lock_guard]]. Функция `push` оповещает ровно один ожидающий поток о том, что в очереди появился новый элемент (строка `condVar.notify_one();`). Напомним, что операция `notify_one` над переменной условия сама по себе синхронизации не требует. Возможно, читателя насторожило отсутствие предиката при ожидании в строке `condVar.wait(tailLock);`. Предикат при ожидании переменной условия нужен для защиты от утерянных и ложных пробуждений. Однако здесь с этим справляется предшествующая проверка на логическую пустоту. Остаётся завершить рассказ о потокобезопасной очереди примером запуска этой программы.

![[ParallelProg_255.png]]

