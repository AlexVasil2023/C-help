
1. [[#Параллельное программирование и современный язык C++|Параллельное программирование и современный язык C++]]
2. [[#Стандарты C++11 и C++14 закладка фундамента|Стандарты C++11 и C++14: закладка фундамента]]
	1. [[#Модели памяти|Модели памяти]]
		1. [[#Атомарные переменные|Атомарные переменные]]
	2. [[#Управление потоками|Управление потоками]]
		1. [[#Классы для поддержки потоков|Классы для поддержки потоков]]
			1. [[#Базовые потоки типа std thread|Базовые потоки типа std thread]]
			2. [[#Усовершенствованные потоки класс std jthread (стандарт С++ 20)|Усовершенствованные потоки класс std jthread (стандарт С++ 20)]]
		2. [[#Данные в совместном доступе|Данные в совместном доступе]]
			1. [[#Мьютексы|Мьютексы]]
			2. [[#Блокировщики|Блокировщики]]
			3. [[#Потокобезопасная инициализация|Потокобезопасная инициализация]]
		3. [[#Локальные данные потока|Локальные данные потока]]
		4. [[#Переменные условия|Переменные условия]]
		5. [[#Кооперативное прерывание потоков (стандарт C++20)|Кооперативное прерывание потоков (стандарт C++20)]]
		6. [[#Семафоры (стандарт C++ 20)|Семафоры (стандарт C++ 20)]]
		7. [[#Защёлки и барьеры (стандарт C++ 20)|Защёлки и барьеры (стандарт C++ 20)]]
		8. [[#Задания|Задания]]
		9. [[#Синхронизированные потоки вывода (стандарт С++ 20)|Синхронизированные потоки вывода (стандарт С++ 20)]]
3. [[#Стандарт C++ 17. Параллельные алгоритмы в стандартной библиотеке|Стандарт C++ 17. Параллельные алгоритмы в стандартной библиотеке]]
	2. [[Политики выполнения#Политики выполнения|Политики выполнения]] 4.1
		1. [[Политики выполнения#Параллельное и векторизованное выполнение|Параллельное и векторизованное выполнение]] 4.1.1
			1. [[Политики выполнения#Код без оптимизации|Код без оптимизации]] 4.1.1.1
			2. [[Политики выполнения#Максимальная оптимизация|Максимальная оптимизация]] 4.1.1.2
		2. [[Политики выполнения#Обработка исключений|Обработка исключений]] 4.1.2
		3. [[Политики выполнения#Опасность гонок данных и мёртвых блокировок|Опасность гонок данных и мёртвых блокировок]] 4.1.3
	3. [[Алгоритмы стандартной библиотеки#Алгоритмы стандартной библиотеки|Алгоритмы стандартной библиотеки]] 4.2
	4. [[Новые параллельные алгоритмы#Новые параллельные алгоритмы|Новые параллельные алгоритмы]] 4.3
		1. [[Новые параллельные алгоритмы#Новые перегрузки|Новые перегрузки]] 4.3.1
		2. [[Новые параллельные алгоритмы#Наследие функционального программирования|Наследие функционального программирования]] 4.3.2
	5. [[Поддержка параллельных алгоритмов#Поддержка параллельных алгоритмов|Поддержка параллельных алгоритмов]] 4.4
4. [[#Сопрограммы в стандарте C++ 20|Сопрограммы в стандарте C++ 20]]
	1. [[Func-Generator#Функция-генератор|Функция-генератор]] 5.1
	2. [[Особенности сопрограмм#Особенности сопрограмм|Особенности сопрограмм]] 5.2
		1. [[Особенности сопрограмм#Типичные сценарии использования|Типичные сценарии использования]] 5.2.1
		2. [[Особенности сопрограмм#Разновидности сопрограмм|Разновидности сопрограмм]] 5.2.2
		3. [[Особенности сопрограмм#Требования к сопрограммам|Требования к сопрограммам]] 5.2.3
		4. [[Особенности сопрограмм#Преобразование функции в сопрограмму|Преобразование функции в сопрограмму]] 5.2.4
		5. [[Особенности сопрограмм#Ограничения|Ограничения]] 5.2.5
	3. [[Концептуальная модель#Концептуальная модель|Концептуальная модель]] 5.3
		1. [[Концептуальная модель#Объект-обещание|Объект-обещание]] 5.3.1
		2. [[Концептуальная модель#Дескриптор сопрограммы|Дескриптор сопрограммы]] 5.3.2
		3. [[Концептуальная модель#Кадр сопрограммы|Кадр сопрограммы]] 5.3.3
	5. [[Ожидание отложенного вычисления#Ожидание отложенного вычисления|Ожидание отложенного вычисления]] 5.4
		1. [[Ожидание отложенного вычисления#Прообраз ожидания|Прообраз ожидания]] 5.4.1
		2. [[Ожидание отложенного вычисления#Общие требования к контроллерам ожидания|Общие требования к контроллерам ожидания]] 5.4.2
		3. [[Ожидание отложенного вычисления#Стандартные контроллеры ожидания|Стандартные контроллеры ожидания]] 5.4.3
		4. [[Ожидание отложенного вычисления#Функция initial_suspend|Функция initial_suspend]] 5.4.4
		5. [[Ожидание отложенного вычисления#Функция final_suspend|Функция final_suspend]] 5.4.5
		6. [[Ожидание отложенного вычисления#Получение контроллера ожидания|Получение контроллера ожидания]] 5.4.6
	6. [[Процесс функционирования сопрограммы#Процесс функционирования сопрограммы|Процесс функционирования сопрограммы]] 5.5
		1. [[Процесс функционирования сопрограммы#Управление обещанием|Управление обещанием]] 5.5.1
		2. [[Процесс функционирования сопрограммы#Управление ожиданием|Управление ожиданием]] 5.5.2
	7. [[Оператор co_return и жадный фьючерс#Оператор co_return и жадный фьючерс|Оператор co_return и жадный фьючерс]] 5.6
	8. [[Оператор co_yield и бесконечный поток данных#Оператор co_yield и бесконечный поток данных|Оператор co_yield и бесконечный поток данных]] 5.7
	9. [[Оператор co_await#Оператор co_await|Оператор co_await]] 5.8
		1. [[Оператор co_await#Запуск задания по запросу|Запуск задания по запросу]] 5.8.1
	10. [[Синхронизация потоков#Синхронизация потоков|Синхронизация потоков]] 5.9
5. Учебные примеры 6
	1. [[Вычисление суммы элементов вектора#Вычисление суммы элементов вектора|Вычисление суммы элементов вектора]] 6.1
		1. [[Вычисление суммы элементов вектора#Суммирование элементов вектора в одном потоке|Суммирование элементов вектора в одном потоке]] 6.1.1
			1. [[Вычисление суммы элементов вектора#Суммирование в цикле по диапазону|Суммирование в цикле по диапазону]] 6.1.1.1
			2. [[Вычисление суммы элементов вектора#Суммирование алгоритмом std accumulate|Суммирование алгоритмом std::accumulate]] 6.1.1.2
			3. [[Вычисление суммы элементов вектора#Использование блокировщика|Использование блокировщика]] 6.1.1.3
			4. [[Вычисление суммы элементов вектора#Использование атомарной переменной|Использование атомарной переменной]] 6.1.1.4
			5. [[Вычисление суммы элементов вектора#Сводные данные по однопоточным алгоритмам|Сводные данные по однопоточным алгоритмам]] 6.1.1.5
		2. [[Вычисление суммы элементов вектора#Многопоточное суммирование с общей переменной|Многопоточное суммирование с общей переменной]] 6.1.2
			1. [[Вычисление суммы элементов вектора#Использование блокировщика|Использование блокировщика]] 6.1.2.1
			2. [[Вычисление суммы элементов вектора#Использование атомарной переменной|Использование атомарной переменной]] 6.1.2.2
			3. [[Вычисление суммы элементов вектора#Использование атомарной переменной с функцией fetch_add|Использование атомарной переменной с функцией fetch_add]] 6.1.2.3
			4. [[Вычисление суммы элементов вектора#Использование ослабленной семантики|Использование ослабленной семантики]] 6.1.2.4
			5. [[Вычисление суммы элементов вектора#Сводные данные по алгоритмам с общей переменной|Сводные данные по алгоритмам с общей переменной]] 6.1.2.5
		3. [[Вычисление суммы элементов вектора#Раздельное суммирование в потоках|Раздельное суммирование в потоках]] 6.1.3
			1. [[Вычисление суммы элементов вектора#Использование локальной переменной|Использование локальной переменной]] 6.1.3.1 
				1. [[Вычисление суммы элементов вектора#Синхронизация итоговой суммы блокировщиком std lock_guard|Синхронизация итоговой суммы блокировщиком std::lock_guard]] 6.1.3.1.1
				2. [[Вычисление суммы элементов вектора#Сумма в атомарной переменной с последовательной согласованностью|Сумма в атомарной переменной с последовательной согласованностью]] 6.1.3.1.2
				3. [[Вычисление суммы элементов вектора#Использование атомарной переменной с ослабленной семантикой|Использование атомарной переменной с ослабленной семантикой]] 6.1.3.1.3
			2. [[Вычисление суммы элементов вектора#Использование переменных с потоковым временем жизни|Использование переменных с потоковым временем жизни]] 6.1.3.2
			3. [[Вычисление суммы элементов вектора#Использование асинхронных заданий|Использование асинхронных заданий]] 6.1.3.3
			4. [[Вычисление суммы элементов вектора#Сводные данные|Сводные данные]] 6.1.3.4
		4. [[Вычисление суммы элементов вектора#Суммирование вектора подведение итогов|Суммирование вектора: подведение итогов]] 6.1.4
			1. [[Вычисление суммы элементов вектора#Однопоточные алгоритмы|Однопоточные алгоритмы]] 6.1.4.1
			2. [[Вычисление суммы элементов вектора#Многопоточные алгоритмы с общей переменной|Многопоточные алгоритмы с общей переменной]] 6.1.4.2
			3. [[Вычисление суммы элементов вектора#Многопоточные алгоритмы с локальными переменными|Многопоточные алгоритмы с локальными переменными]] 6.1.4.3
	2. [[Потокобезопасное создание объекта-одиночки#Потокобезопасное создание объекта-одиночки|Потокобезопасное создание объекта-одиночки]] 6.2
		1. [[Потокобезопасное создание объекта-одиночки#Шаблон «Блокировка с двойной проверкой»|Шаблон «Блокировка с двойной проверкой»]] 6.2.1
		2. [[Потокобезопасное создание объекта-одиночки#Измерение производительности|Измерение производительности]] 6.2.2
		3. [[Потокобезопасное создание объекта-одиночки#Потокобезопасный вариант реализации Мейерса|Потокобезопасный вариант реализации Мейерса]] 6.2.3
		4. [[Потокобезопасное создание объекта-одиночки#Реализации на основе блокировщика|Реализации на основе блокировщика]] 6.2.4
		5. [[Потокобезопасное создание объекта-одиночки#Реализация на основе функции std call_once|Реализация на основе функции std::call_once]] 6.2.5
		6. [[Потокобезопасное создание объекта-одиночки#Решение на основе атомарных переменных|Решение на основе атомарных переменных]] 6.2.6
			1. [[Потокобезопасное создание объекта-одиночки#Семантика последовательной согласованности|Семантика последовательной согласованности]] 6.2.6.1
			2. [[Потокобезопасное создание объекта-одиночки#Семантика захвата и освобождения|Семантика захвата и освобождения]] 6.2.6.2
		7. [[Потокобезопасное создание объекта-одиночки#Сводные данные|Сводные данные]] 6.2.7 
	3. [[оптимизация с использованием CppMem#Поэтапная оптимизация с использованием инструмента CppMem|Поэтапная оптимизация с использованием инструмента CppMem]] 6.3
		1. [[оптимизация с использованием CppMem#Неатомарные переменные|Неатомарные переменные]] 6.3.1
			1. [[оптимизация с использованием CppMem#Анализ программы|Анализ программы]] 6.3.1.1
				1. [[оптимизация с использованием CppMem#Первый вариант выполнения|Первый вариант выполнения]] 6.3.1.1.1
				2. [[оптимизация с использованием CppMem#Второй вариант выполнения|Второй вариант выполнения]] 6.3.1.1.2
				3. [[оптимизация с использованием CppMem#Третий вариант выполнения|Третий вариант выполнения]] 6.3.1.1.3
				4. [[оптимизация с использованием CppMem#Четвёртый вариант выполнения|Четвёртый вариант выполнения]] 6.3.1.1.4
				5. [[оптимизация с использованием CppMem#Выводы|Выводы]] 6.3.1.1.5
		2. [[оптимизация с использованием CppMem#Анализ программы с блокировкой|Анализ программы с блокировкой]] 6.3.2
		3. [[оптимизация с использованием CppMem#Атомарные переменные с последовательной согласованностью|Атомарные переменные с последовательной согласованностью]] 6.3.3
			1. [[оптимизация с использованием CppMem#Анализ программы инструментом CppMem|Анализ программы инструментом CppMem]] 6.3.3.1
				1. [[оптимизация с использованием CppMem#Вариант выполнения для y = 0, x = 0|Вариант выполнения для y = 0, x = 0]] 6.3.3.1.1
				2. [[оптимизация с использованием CppMem#Варианты выполнения для y = 0, x = 2000|Варианты выполнения для y = 0, x = 2000]] 6.3.3.1.2
				3. [[оптимизация с использованием CppMem#Вариант выполнения для y = 11, x = 2000|Вариант выполнения для y = 11, x = 2000]] 6.3.3.1.3
			2. [[оптимизация с использованием CppMem#Последовательность операций|Последовательность операций]] 6.3.3.2
		4. [[оптимизация с использованием CppMem#Атомарные переменные с семантикой захвата и освобождения|Атомарные переменные с семантикой захвата и освобождения]] 6.3.4
			1. [[оптимизация с использованием CppMem#Анализ программы инструментом CppMem 2|Анализ программы инструментом CppMem]] 6.3.4.1
				1. [[оптимизация с использованием CppMem#Возможные варианты выполнения|Возможные варианты выполнения]] 6.3.4.1.1
				2. [[оптимизация с использованием CppMem#Вариант выполнения для случая y = 0, x = 0|Вариант выполнения для случая y = 0, x = 0]] 6.3.4.1.2
				3. [[оптимизация с использованием CppMem#Вариант выполнения для случая y = 0, x = 2000|Вариант выполнения для случая y = 0, x = 2000]] 6.3.4.1.3
				4. [[оптимизация с использованием CppMem#Вариант выполнения для случая y = 11, x = 2000|Вариант выполнения для случая y = 11, x = 2000]] 6.3.4.1.4
		5. [[оптимизация с использованием CppMem#Смесь атомарных и неатомарных переменных|Смесь атомарных и неатомарных переменных]] 6.3.5
			1. [[оптимизация с использованием CppMem#Анализ программы инструментом CppMem 3|Анализ программы инструментом CppMem]] 6.3.5.1
		6. [[оптимизация с использованием CppMem#Атомарные переменные с ослабленной семантикой|Атомарные переменные с ослабленной семантикой]] 6.3.6
			1. [[оптимизация с использованием CppMem#Анализ инструментом CppMem 4|Анализ инструментом CppMem]] 6.3.6.1
	4. [[Быстрая синхронизация потоков#Быстрая синхронизация потоков|Быстрая синхронизация потоков]] 6.4
		1. [[Быстрая синхронизация потоков#Переменные условия|Переменные условия]] 6.4.1
		2. [[Быстрая синхронизация потоков#Решение на основе атомарного флага|Решение на основе атомарного флага]] 6.4.2
			1. [[Быстрая синхронизация потоков#Решение с двумя флагами|Решение с двумя флагами]] 6.4.2.1
			2. [[Быстрая синхронизация потоков#Решение с одним атомарным флагом|Решение с одним атомарным флагом]] 6.4.2.2
		3. [[Быстрая синхронизация потоков#Решение на основе атомарной логической переменной|Решение на основе атомарной логической переменной]] 6.4.3
		4. [[Быстрая синхронизация потоков#Реализация на семафорах|Реализация на семафорах]] 6.4.4
		5. [[Быстрая синхронизация потоков#Сравнительный анализ|Сравнительный анализ]] 6.4.5
	5. [[Вариации на тему фьючерсов#Вариации на тему фьючерсов|Вариации на тему фьючерсов]] 6.5
		1. [[Вариации на тему фьючерсов#Ленивый фьючерс|Ленивый фьючерс]] 6.5.1
		2. [[Вариации на тему фьючерсов#Выполнение сопрограммы в отдельном потоке|Выполнение сопрограммы в отдельном потоке]] 6.5.2
	6. [[Модификации и обобщения генераторов#Модификации и обобщения генераторов|Модификации и обобщения генераторов]] 6.6
		1. [[Модификации и обобщения генераторов#Модификации программы|Модификации программы]] 6.6.1
			1. [[Модификации и обобщения генераторов#Если сопрограмму не пробуждать|Если сопрограмму не пробуждать]] 6.6.1.1
			2. [[Модификации и обобщения генераторов#Сопрограмма не приостанавливается на старте|Сопрограмма не приостанавливается на старте]] 6.6.1.2
			3. [[Модификации и обобщения генераторов#Сопрограмма не приостанавливается при выдаче значения|Сопрограмма не приостанавливается при выдаче значения]] 6.6.1.3
		2. [[Модификации и обобщения генераторов#Обобщение|Обобщение]] 6.6.2
	7. [[Способы управления заданиями#Способы управления заданиями|Способы управления заданиями]] 6.7
		1. [[Способы управления заданиями#Функционирование контроллера ожидания|Функционирование контроллера ожидания]] 6.7.1
		2. [[Способы управления заданиями#Автоматическое возобновление работы|Автоматическое возобновление работы]] 6.7.2
		3. [[Способы управления заданиями#Автоматическое пробуждение сопрограммы в отдельном потоке|Автоматическое пробуждение сопрограммы в отдельном потоке]] 6.7.3
7. [[#Будущее языка C++|Будущее языка C++]]
	1. [[executor|Исполнители]] 7.1
		1. [[executor#Долгий путь исполнителя|Долгий путь исполнителя]] 7.1.1
		2. [[executor#Что такое исполнитель|Что такое исполнитель]] 7.1.2
			1. [[executor#Свойства исполнителя|Свойства исполнителя]] 7.1.2.1
		3. [[executor#Первые примеры|Первые примеры]] 7.1.3
			1. [[executor#Использование исполнителя|Использование исполнителя]] 7.1.3.1
				1. [[executor#Асинхронное обещание|Асинхронное обещание]] 7.1.3.1.1
				2. [[executor#Обход элементов контейнера|Обход элементов контейнера]] 7.1.3.1.2
				3. [[executor#Сетевое соединение с использованием системного исполнителя|Сетевое соединение с использованием системного исполнителя]] 7.1.3.1.3
				4. [[executor#Сетевое соединение с использованием явно заданного исполнителя|Сетевое соединение с использованием явно заданного исполнителя]] 7.1.3.1.4
			2. [[executor#Получение исполнителя|Получение исполнителя]] 7.1.3.2
				1. [[executor#Получение исполнителя из статического пула потоков|Получение исполнителя из статического пула потоков]] 7.1.3.2.1
				2. [[executor#Получение исполнителя из параллельной политики выполнения|Получение исполнителя из параллельной политики выполнения]] 7.1.3.2.2
				3. [[executor#Системный исполнитель по умолчанию|Системный исполнитель по умолчанию]] 7.1.3.2.3
				4. [[executor#Применение адаптера к существующему исполнителю|Применение адаптера к существующему исполнителю]] 7.1.3.2.4
		4. [[executor#Цели разработки исполнителей|Цели разработки исполнителей]] 7.1.4
		5. [[executor#Терминология|Терминология]] 7.1.5
		6. 
				1. 
				2. 
				3. 
		7. 
	2. 
	3. [[#Расширенные фьючерсы|Расширенные фьючерсы]]
	4. [[#Транзакционная память|Транзакционная память]]
	5. [[#Блоки заданий|Блоки заданий]]
	6. [[#Библиотека для векторных вычислений|Библиотека для векторных вычислений]]
9. [[#Шаблоны и эмпирические правила]]
	1. [[#Шаблоны синхронизации|Шаблоны синхронизации]]
	2. [[#Шаблоны параллельной архитектуры|Шаблоны параллельной архитектуры]]
	3. [[#Эмпирические правила|Эмпирические правила]]
10. [[#Структуры данных|Структуры данных]]
11. [[#Сложности параллельного программирования|Сложности параллельного программирования]]
12. [[#Библиотека для работы со временем|Библиотека для работы со временем]]
13. [[#Обзор инструментального средства CppMem|Обзор инструментального средства CppMem]]

# Параллельное программирование и современный язык C++

С выходом стандарта C++11 язык получил библиотеку для многопоточного программирования и подходящую модель памяти. Эта библиотека содержит такие строительные блоки, как атомарные переменные, классы для потоков, двоичных семафоров и переменных условия. Они составляют фундамент, на котором в будущих версиях стандарта – например, С++20 и C++23 – станет возможным определить абстракции более высокого уровня. Однако и в стандарте C++11 уже присутствует понятие задания, которое обеспечивает более высокий уровень абстрагирования по сравнению с перечисленными базовыми строительными блоками.

![[ParallelProg.png]]

С некоторым огрублением историю поддержки параллельных вычислений в языке C++ можно разделить на три периода, которые кратко описаны
далее.

## Стандарты C++11 и C++14: закладка фундамента

Стандартом C++11 поддержка многопоточного программирования впервые добавлена в язык. Она состоит из чётко определённой модели памяти и интерфейса для программирования потоков. С выходом стандарта C++14 к этому набору добавлены блокировщики чтения-записи.

### Модели памяти

==см. [[Memory model#Модель памяти|Модель памяти]]==

#### Атомарные переменные

Язык C++ содержит набор простых атомарных типов данных. К ним относятся логические, символьные, числовые типы и типы указателей, включая различные их вариации. Программист может определить собственный атомарный тип данных, воспользовавшись шаблоном класса [[atomic|std::atomic]]. Этот шаблон позволяет наложить требования синхронизации и упорядочения операций на типы, сами по себе не являющиеся атомарными.

Стандартизированный интерфейс управления потоками – это ядро всей системы средств параллельного программирования на языке C++.

==Детально см. [[Memory model#Атомарные переменные|Атомарные переменные]]==

### Управление потоками

![[ParallelProg_3.png]]

Средства многопоточного программирования в языке C++ включают потоки, примитивы синхронизации доступа к общим данным, локальные переменные потоков и задания.

==Детально см. [[Thread Management|Управление потоками]]==

#### Классы для поддержки потоков

В библиотеке языка C++ есть два класса для поддержки потоков: простейший [[thread#std thread|std::thread]], введённый в стандарте C++11, и усовершенствованный [[thread#std jthread|std::jthread]], появившийся в стандарте C++20.

##### Базовые потоки типа std::thread

==см. [[thread#Базовые потоки класс std thread|std::thread]]==

##### Усовершенствованные потоки: класс std::jthread (стандарт С++ 20)

==см. [[thread#std jthread|std::jthread]]==
#### Данные в совместном доступе

Программисту необходимо координировать доступ к общей переменной, если более одного потока могут одновременно обращаться к ней и если переменная при этом может менять своё значение (т.е. не является константой). Чтение данных из общей переменной в то время, как другой поток помещает в неё новое значение, называется гонкой данных и представляет собой неопределённое поведение. Координация доступа к общей переменной достигается в языке C++ с помощью [[mutex#std mutex|мьютексов]] и блокировщиков.

см. [[thread#Данные в совместном доступе|Данные в совместном доступе]]

##### Мьютексы

==см. [[mutex#std mutex|Мьютекс]]==

##### Блокировщики

Чтобы гарантировать автоматическое освобождение мьютекса, его следует оборачивать в объект-блокировщик (lock). Блокировщики реализуют идиому RAII – время запирания мьютекса ограничивается временем жизни блокировщика. В стандарте языка имеются классы [[lock#Тип std lock_guard|std::lock_guard]] и [[lock#Тип std scoped_lock|std::scoped_lock]] для простых сценариев использования и классы [[lock#Тип std unique_lock|std::unique_lock]] и [[lock#Блокировщик std shared_lock|std::shared_lock]] – для более сложных (например, для явного освобождения и повторного запирания [[mutex|мьютекса]]).

см. [[lock|Блокировщики]]

##### Потокобезопасная инициализация

Если общие данные используются только для чтения, достаточно обеспечить потокобезопасность их инициализации. Язык C++ предоставляет для этого множество средств, включая константные выражения, статические переменные, видимые в определённом блоке, или функцию [[call_once|std::call_once]] вместе с флагом `std::once_flag`.

см. [[Thread_Safe initialization#Потокобезопасная инициализация|Потокобезопасная инициализация]]

#### Локальные данные потока

Объявление переменной как локальной для потока (англ. thread-local) означает, что каждый поток получит собственную копию такой переменной. В этом случае переменная уже не будет общей для нескольких потоков. Время жизни локальных данных потока ограничено временем выполнения потока-хозяина.

см. [[ThreadLocal#Данные с потоковой длительностью хранения|Данные с потоковой длительностью хранения]]

#### Переменные условия

Переменные условия (англ. condition variables) позволяют синхронизировать потоки путём отправки сообщений. Один поток выступает отправителем оповещения, а остальные – получателями. Типичная ситуация, для которой хорошо подходят переменные условия, – это очередь между производителями и потребителями данных. При этом условную переменную может использовать как отправитель, так и получатель сообщения. Использование переменных условия может оказаться непростым делом; зачастую более простых решений можно добиться на основе т.н. заданий.

см. [[variable conditions#Переменные условия|Переменные условия]]

#### Кооперативное прерывание потоков (стандарт C++20)

Полезное дополнение к средствам управления потоками состоит в возможности прерывать их выполнение – при условии, что в коде потока расставлены точки, где его можно прерывать. Такое прерывание называется кооперативным. Кооперативное прерывание поддерживается классами [[thread#std jthread|std::jthread]] и [[variable conditions|std::condition_variable]], для его реализации служат классы [[Кооперативное прерывание потоков#Класс std stop_source|std::stop_source]], [[Кооперативное прерывание потоков#Класс std stop_token|std::stop_token]] и [[Кооперативное прерывание потоков#Класс std stop_callback|std::stop_callback]].

см. [[Кооперативное прерывание потоков#Кооперативное прерывание потоков|Кооперативное прерывание потоков]]
#### Семафоры (стандарт C++ 20)

==см. [[semaphore#|Семафоры]]==

#### Защёлки и барьеры (стандарт C++ 20)

Защёлки и барьеры служат для координирования потоков. Они позволяют блокировать поток до тех пор, пока счётчик не достигнет нуля. Начальное значение счётчика задаётся в конструкторе. Несмотря на сходство названий, барьеры, о которых говорится здесь, не имеют ничего общего с барьерами памяти, на которых основана семантика атомарных операций. Для координации потоков через счётчики служат два класса: [[Latch_and_Barrier#Класс std latch|std::latch]] и [[Latch_and_Barrier#Класс std barrier|std::barrier]]. Одновременный вызов функций-членов объекта такого класса из разных потоков никогда не приводит к гонке данных.

см. [[Latch_and_Barrier|Защёлки и барьеры (стандарт C++20)]]
#### Задания

==см. [[task|std::task]]== и ==[[asyncVersus#Асинхронные задания|Асинхронные задания]]==

#### Синхронизированные потоки вывода (стандарт С++ 20)

==см. [[basic_syncbuf#std basic_syncbuf|std::basic_syncbuf]]==

## Стандарт C++ 17. Параллельные алгоритмы в стандартной библиотеке

![[ParallelProgr_5.png]]

С появлением стандарта C++ 17 поддержка параллельного программирования языком C++ значительно расширилась, особенно за счёт параллельных алгоритмов. Стандарты C++11 и C++14 содержали лишь простейшие строительные блоки для создания параллельных программ. Эти инструменты были удобны для разработки библиотек или каркасов, но не для разработки приложений. По сравнению со средствами параллельного программирования из стандарта C++17, средства стандартов C++11 и C++14 выглядят словно язык ассемблера.

В стандартной библиотеке языка C++ содержится более ста алгоритмов для поиска, подсчёта и преобразования элементов в контейнерах и их диапазонах. С выходом стандарта C++17 появились 69 новых перегрузок для имеющихся алгоритмов и 8 полностью новых алгоритмов, способных работать параллельно. Новые перегрузки и новые алгоритмы принимают в качестве аргумента так называемую политику выполнения.

С помощью политики выполнения программист может сообщить реализации, должен ли алгоритм выполняться последовательно, параллельно или параллельно с векторизацией. Для того чтобы воспользоваться политикой выполнения, нужно подключить заголовочный файл `<execution>`.

### Политики выполнения

В стандарте C++17 для большинства алгоритмов из стандартной библиотеки стали доступны параллельные версии. Вызывая тот или иной алгоритм, можно передавать ему так называемую политику выполнения. 

C++17 предлагает параметр политики выполнения для большинства алгоритмов:

> - **sequenced_policy** — тип политики выполнения, используется в качестве уникального типа для устранения перегрузки параллельного алгоритма и требования того, что распараллеливание выполнения параллельного алгоритма — невозможно: соответствующий глобальный объект — `std::execution::seq`;
>
> - **parallel_policy** — тип политики выполнения, используемый в качестве уникального типа для устранения перегрузки параллельного алгоритма и указания на то, что распараллеливание выполнения параллельного алгоритма — возможно: соответствующий глобальный объект — `std::execution::par`;
> 
>- **parallel_unsequenced_policy** — тип политики выполнения, используемый в качестве уникального типа для устранения перегрузки параллельного алгоритма и указания на то, что распараллеливание и векторизация выполнения параллельного алгоритма — возможны: соответствующий глобальный объект — `std::execution::par_unseq`;

Кратко:

> - используйте `std::execution::seq` для последовательного выполнения алгоритма;


>- используйте `std::execution::par` для параллельного выполнения алгоритма (обычно с помощью какой-либо реализации Thread Pool (пула потоков));

>- используйте `std::execution::par_unseq` для параллельного выполнения алгоритма с возможностью использования векторных команд (например, SSE, AVX).

см. [[Политики выполнения#Политики выполнения|Политики выполнения]]

### Новые параллельные алгоритмы

В дополнение к 69 старым алгоритмам, получившим возможность выполняться параллельным или параллельно-векторизированным способом, библиотека пополнилась восемью новыми алгоритмами. Эти алгоритмы, предназначенные для свёртки, сканирования и преобразования контейнеров, изначально приспособлены для параллельного выполнения.

см. [[Новые параллельные алгоритмы#Новые параллельные алгоритмы|Новые параллельные алгоритмы]]

## Сопрограммы в стандарте C++ 20

![[ParallelProg_6.png]]

Сопрограммы можно представить себе как функции, выполнение которых можно приостанавливать, сохраняя текущее состояние, а затем возобновлять. Сопрограммы хорошо подходят для реализации кооперативной многозадачности, как в некоторых операционных системах, циклов обработки событий, бесконечных списков и конвейеров.

> **Трудность понимания сопрограмм**
> 
> Понять сопрограммы оказалось поначалу непросто даже для автора этой книги. Читателю рекомендуется при первом знакомстве с данной главой пропустить разделы о концептуальной модели и процессе функционирования и сосредоточиться на примерах из разделов «Вариации на тему фьючерса», «Модификации и обобщения генератора» и «Варианты жизненного цикла задания». Внимательное изучение примеров и самостоятельные эксперименты с ними должны выработать у читателя начальное понимание, с которым можно погружаться в подробности и тонкости работы с сопрограммами.

То, о чём в этом разделе говорится как о новшестве стандарта C++20, на самом деле представляет собой довольно старую идею. Впервые термин «сопрограмма» ввёл Мелвин Конуэй. Он использовал данное понятие в своей публикации 1963 года, посвящённой построению компиляторов. Дональд Кнут назвал процедуры частным случаем сопрограмм. Иногда проходит немало времени, прежде чем идея получает признание.

![[ParallelProg_108.png]]

Если функцию можно лишь вызвать и, по завершении её работы, получить результат, то сопрограмму можно вызвать, получить промежуточный результат, обработать его, пока работа сопрограммы приостановлена, затем продолжить или прервать её выполнение.

В стандарте C++ 20 появились два новых ключевых слова: `co_await` и `co_yield`, а понятие выполнения функции соответственно расширено.

Ключевое слово `co_await` позволяет приостанавливать и возобновлять вычисление выражения. Если конструкцию вида `co_awai expression` использовать в функции `func`, операция `auto getResult = func()` не блокирует выполнение вызывающего кода, если результат функции ещё не готов. Вместо блокирования, требующего значительных ресурсов, здесь имеет место легковесное ожидание.

Ключевое слово `co_yield` позволяет создавать функции-генераторы. Такая функция возвращает очередной элемент последовательности каждый раз, когда её вызывают. Функцию-генератор можно рассматривать как своего рода поток, из которого можно получать значения одно за другим. Этот поток может быть бесконечным. Таким образом, на основе сопрограмм можно реализовать на языке C++ парадигму ленивых вычислений.


## Будущее языка C++

![[ParallelProgr7.png]]

см. [[Будущее языка#Будущее языка|Будущее языка]]

### Исполнители

==см. [[executor|executor]]==

### Расширенные фьючерсы

==см. [[future#Расширенные фьючерсы|Расширенные фьючерсы]]==

### Транзакционная память

==см. [[transaction Memory]]==

### Блоки заданий

==см. [[task#Блоки заданий|Блоки заданий]]==

### Библиотека для векторных вычислений

Библиотека для векторных вычислений позволяет воспользоваться распараллеливанием по данным (SIMD – англ. single instructions, multiple data) при работе с векторными типами. Этот принцип вычислений состоит в том, что каждая операция может выполняться параллельно над несколькими значениями.

## Шаблоны и эмпирические правила

Шаблоны – это хорошо документированные методики, лучшие из устоявшихся на практике. Они «выражают отношение между определённым контекстом, проблемой и решением» (Кристофер Александер). Рассматривая трудности параллельного программирования с более фундаментальной точки зрения, можно получить немалую выгоду. В отличие от главы о шаблонах, глава об устоявшихся практиках посвящена более прагматичным советам о том, как преодолевать те или иные затруднения.

### Шаблоны синхронизации

Необходимое условие для возникновения гонок данных – наличие общего доступа потоков к изменяемому состоянию. Шаблоны синхронизации сводятся к двум вопросам: что делать с общим доступом и что делать с изменяемым состоянием.

### Шаблоны параллельной архитектуры

==см. [[parallel architecture patterns#Шаблоны параллельной архитектуры|Шаблоны параллельной архитектуры]]==

### Эмпирические правила

Параллельное программирование сложно по самой своей сути, поэтому имеет смысл пользоваться накопленным практическим опытом – как в области параллельного программирования в целом, так и, в частности, в том, что касается управления потоками и моделей памяти.

## Структуры данных

Структура данных, которая защищает себя сама таким образом, что гонка данных в ней становится невозможной, называется потокобезопасной. Отдельная глава посвящена трудностям, возникающим при разработке потокобезопасных структур данных с блокировками.

## Сложности параллельного программирования

Создание параллельных программ – сложное дело. Особенно сложным оно становится, если использовать только лишь средства из стандартов C++11 и C++14. Поэтому в отдельной главе рассказывается о наиболее существенных трудностях. 

## Библиотека для работы со временем

Средства для работы со временем тесно связаны со средствами параллельного программирования. Часто возникает необходимость приостановить выполнение потока на определённый промежуток времени или до наступления определённого момента времени. В состав стандартной библиотеки входят: моменты времени, временные интервалы и часы.

## Обзор инструментального средства CppMem

**CppMem** – это интерактивный инструмент, позволяющий заглянуть глубоко внутрь модели памяти. Он предоставляет две замечательные услуги. Во-первых, с его помощью можно верифицировать свой безблокировочный код; во-вторых, можно проанализировать безблокировочный код и получить более точное представление о том, как он работает. В этой книге инструмент CppMem используется часто. Поскольку параметры конфигурации и механизмы работы CppMem довольно сложны, глава даёт лишь общее представление об этом инструменте.




