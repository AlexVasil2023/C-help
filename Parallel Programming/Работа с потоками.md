
[[#Работа с потоками|Работа с потоками]] 11.2
1. [[#Общие вопросы многопоточного программирования|Общие вопросы многопоточного программирования]] 11.2.1
	1. [[#Создание как можно меньшего числа потоков|Создание как можно меньшего числа потоков]] 11.2.1.1
		1. [[#Затраты памяти|Затраты памяти]] 11.2.1.1.1
		2. [[#Затраты на создание потока|Затраты на создание потока]] 11.2.1.1.2
		3. [[#Система Linux|Система Linux]] 11.2.1.1.3
		4. [[#Система Windows|Система Windows]] 11.2.1.1.4
	2. [[#Использование заданий вместо потоков|Использование заданий вместо потоков]] 11.2.1.2
	3. [[#Особая осторожность при отсоединении потока|Особая осторожность при отсоединении потока]] 11.2.1.3
	4. [[#Предпочтительность потоков с автоматическим присоединением|Предпочтительность потоков с автоматическим присоединением]] 11.2.1.4
2. [[#Управление доступом к данным|Управление доступом к данным]] 11.2.2
	1. [[#Передача данных по значению|Передача данных по значению]] 11.2.2.1
	2. [[#Использование умного указателя для совместного владения данными|Использование умного указателя для совместного владения данными]] 11.2.2.2
	3. [[#Сокращение времени блокировки|Сокращение времени блокировки]] 11.2.2.3
	4. [[#Обёртывание мьютекса в блокировщик|Обёртывание мьютекса в блокировщик]] 11.2.2.4
	5. [[#Предпочтительный захват одного мьютекса|Предпочтительный захват одного мьютекса]] 11.2.2.5
	6. [[#Необходимость давать блокировщикам имена|Необходимость давать блокировщикам имена]] 11.2.2.6
	7. [[#Атомарный захват нескольких мьютексов|Атомарный захват нескольких мьютексов]] 11.2.2.7
	8. [[#Не вызывать неизвестный код под блокировкой|Не вызывать неизвестный код под блокировкой]] 11.2.2.8
3. [[#Переменные условия|Переменные условия]] 11.2.3
	1. [[#Обязательное использование предиката|Обязательное использование предиката]] 11.2.3.1
	2. [[#Замена переменных условия обещаниями и фьючерсами|Замена переменных условия обещаниями и фьючерсами]] 11.2.3.2
4. [[#Обещания и фьючерсы|Обещания и фьючерсы]] 11.2.4
	1. [[#Предпочтительность асинхронных заданий|Предпочтительность асинхронных заданий]] 11.2.4.1

# Работа с потоками

## Общие вопросы многопоточного программирования

Напомним, что потоки – это основные блоки, из которых строятся параллельные программы.

### Создание как можно меньшего числа потоков

Сколь дорого обходится создание потока? Весьма дорого! Именно с этим связано данное эмпирическое правило. Рассмотрим сначала типичные затраты памяти, а затем затраты на процедуру создания потока.

#### Затраты памяти

Объект типа [[thread#std thread|std::thread]] представляет собой тонкую обёртку вокруг потока, находящегося под управлением операционной системы. Поэтому нужно выяснить, сколько памяти занимают потоки в ОС Windows и ОС семейства `Posix`:
* для системы Windows, по заявлению её разработчиков, стек потока занимает 1 мегабайт;
* для систем семейства POSIX, согласно странице руководства `pthread_create`, стек потока имеет размер 2 мегабайта на архитектурах i386 и x86_64. Данные для различных архитектур приведены в следующей таблице.

| **Архитектура** | **Размер стека по умолчинию, Мб** |
| --------------- | --------------------------------- |
| i386            | 2                                 |
| IA-64           | 32                                |
| PowerPC         | 4                                 |
| S/390           | 2                                 |
| Sparc-32        | 2                                 |
| Sparc-64        | 4                                 |
| x86_64          | 2                                 |

#### Затраты на создание потока

Автору не удалось найти в источниках данные о том, сколько времени занимает создание нового потока. Чтобы получить приблизительное представление об этом, понадобилось самостоятельно создать тестовую программу и измерить её производительность в системах Linux и Windows.

Для замера производительности использовался компилятор GCC 6.2.1 на настольной системе и `cl.exe`, входящий в состав среды Microsoft Visual Studio 2017, на переносном компьютере. В обоих случаях программа компилировалась с максимальным уровнем оптимизации: с флагом `O3` в системе Linux и с флагом `Ox` в системе Windows. Исходный текст этой программы показан ниже.

**Программа для измерения скорости создания потоков:**
```c++
// threadCreationPerformance.cpp

#include <chrono>
#include <iostream>
#include <thread>

static const long long numThreads= 1’000’000;

int main(){
	auto start = std::chrono::system_clock::now();

	for (volatile int i = 0; i < numThreads; ++i) 
		std::thread([]{}).detach();

	std::chrono::duration<double> dur =
		std::chrono::system_clock::now() – start;

	std::cout << “time: “ << dur.count() << “ seconds” << std::endl;
}
```

Эта программа создаёт один миллион потоков, в каждом из которых выполняется пустая лямбда-функция, и измеряет понадобившееся для этого суммарное время. В следующих подразделах представлены результаты её работы в двух операционных системах.

#### Система Linux

На следующем рисунке показан результат нескольких запусков тестовой программы.

![[ParallelProg_229.png]]

Из этих данных следует, что в среднем на создание одного потока в системе Linux на данном компьютере тратится около 14,5 микросекунды.

#### Система Windows

Результат нескольких запусков программы показан на следующем рисунке.

![[ParallelProg_230.png]]

Таким образом, в среднем создание каждого потока в системе Windows на данном компьютере обошлось в 44 микросекунды.

Если посмотреть на полученные показатели производительности с противоположной стороны, получим, что за одну секунду на этом компьютере можно создать около 69 тысяч потоков в системе Linux и лишь 23 тысячи – в системе Windows.

### Использование заданий вместо потоков

Рассмотрим следующую программу, в которой одно и то же вычисление выполняется двумя разными способами: в отдельном потоке и в асинхронном задании.

**Сравнение асинхронных заданий с потоками:**
```c++
// asyncVersusThread.cpp

#include <future>
#include <thread>
#include <iostream>

int main(){
	std::cout << std::endl;

	int res;
	std::thread t([&]{ res = 2000 + 11; });
	t.join();

	std::cout << “res: “ << res << std::endl;

	auto fut= std::async([]{ return 2000 + 11; });

	std::cout << “fut.get(): “ << fut.get() << std::endl;
	std::cout << std::endl;
}
```

На примере этой программы можно увидеть несколько причин отдавать предпочтение заданиям, а не потокам. Так, в случае потоков необходим общий доступ к переменной и синхронизация такого доступа. Асинхронные задания, напротив, предоставляют удобный и безопасный канал для передачи результата наружу вычислений, будь то вычисленное значение, оповещение или исключение.

Если использовать [[Расширенные фьючерсы#Расширенные фьючерсы|расширенные фьючерсы]], появляется возможность компоновать фьючерсы между собой, получая таким образом сложные схемы обработки данных. Для этого в первую очередь предназначено продолжение `then` и различные комбинации условий `when_all` и `when_any`.

### Особая осторожность при отсоединении потока

Следующий небольшой фрагмент года должен приковать к себе внимание программиста:

```c++
std::string s{“C++11”}

std::thread t([&s]{ std::cout << s << ‘\n’; });
t.detach();
```

Поток `t` отсоединяется от кода, который его создаёт. При этом могут возникнуть два разных состояния гонки.
5. Время жизни потока `t` может превысить время выполнения блока, в котором он создаётся. В этом случае поток продолжит пользоваться ссылкой на объект `s`, уже прекративший своё существование.
6. Программа может начать своё завершение до того, как поток `t` выполнит свою работу. Это может привести к уничтожению глобального объекта [[cout#std cout|std::cout]], время жизни которого ограничено временем выполнения главного потока программы, в то время как поток `t` всё ещё пытается его использовать.

### Предпочтительность потоков с автоматическим присоединением

Говорят, что поток `t` находится в присоединяемом состоянии, если вызываемый объект в нём присутствует и если не происходили вызовы `t.join()` или `t.detach()`. Деструктор потока, находящегося в присоединяемом состоянии, аварийно завершает программу вызовом функции [[terminate|std::terminate]]. Чтобы не упустить необходимость присоединения потока, можно создать класс-обёртку над классом [[thread#std thread|std::thread]]. Эта обёртка должна проверять, находится ли поток по-прежнему в присоединяемом состоянии, и, если это так, в своём деструкторе дожидаться его завершения с помощью функции `join`.

Программисту нет нужды создавать такую обёртку самостоятельно. Можно воспользоваться готовым классом [[thread#std scoped_thread|scoped_thread]] Энтони Вильямса или классом `gsl::joining_thread` из библиотеки `guideline support library` (https://github.com/Microsoft/GSL. 
#https_github_com_Microsoft_GSL

## Управление доступом к данным

Все трудности многопоточного программирования начинаются там, где появляется совместный доступ к изменяемым данным.

### Передача данных по значению

Рассмотрим следующий код:
```c++
std::string s{“C++11”}

std::thread t1([s]{ ... }); // действия над s
t1.join();

std::thread t2([&s]{ ... }); // действия над s
t2.join();

// действия над s
```

В поток `t1` строка передаётся путём копирования, поэтому поток-создатель и созданный им поток `t1` никак не связаны по данным. Ситуация оказывается иной для потока `t2`. Он получает ссылку на объект `s`. Это означает, что доступ к нему из главного потока и из потока `t2` необходимо синхронизировать. Это чревато ошибками и наносит урон производительности программы.

### Использование умного указателя для совместного владения данными

Пусть имеется объект, к которому нужен доступ из нескольких потоков. Один из важнейших вопросов в этом случае – какой из потоков должен считаться владельцем объекта и, следовательно, отвечает за его уничтожение. Без ответа на него пришлось бы выбирать между утечкой памяти – в случае если занимаемую объектом память не освободит ни один поток – и неопределённым поведением – если потоки пытаются удалить объект более одного раза. Неопределённое поведение чаще всего приводит к краху программы. Следующая программа иллюстрирует этот неразрешимый вопрос.

**Неопределённое владение объектом:**
```c++
// threadSharesOwnership.cpp

#include <iostream>
#include <thread>

using namespace std::literals::chrono_literals;

struct MyInt {
	int val{2017};
	~MyInt() {
		std::cout << “Good Bye” << std::endl;
	}
};

void showNumber(MyInt* myInt) {
	std::cout << myInt->val << std::endl;
}

void threadCreator() {
	MyInt* tmpInt= new MyInt;

	std::thread t1(showNumber, tmpInt);
	std::thread t2(showNumber, tmpInt);

	t1.detach();
	t2.detach();
}

int main() {
	std::cout << std::endl;

	threadCreator();
	std::this_thread::sleep_for(1s);

	std::cout << std::endl;
}
```

Этот пример намеренно сделан предельно простым. Главный поток засыпает на одну секунду, чтобы дать потокам `t1` и `t2` время завершиться. Конечно же, такой механизм синхронизации никак нельзя назвать приемлемым для разработки реальных программ, но для задач данного раздела он подходит. Ключевой вопрос теперь звучит так: какой поток должен удалить объект `tmpInt`? В этом примере возможных вариантов три: это может быть поток `t1`, `t2` или главный поток. Однако, поскольку невозможно предсказать продолжительность работы каждого потока, пришлось смириться с утечкой памяти. Поэтому деструктор объекта никогда не вызывается, в чём легко убедиться, запустив программу.

![[ParallelProg_231.png]]

Управление временем жизни объекта становится довольно лёгкой задачей, если воспользоваться умным указателем [[shared_ptr|std::shared_ptr]]. Ниже приведён текст реализации.

**Управление временем жизни объекта через умный указатель:**
```c++
// threadSharesOwnershipSharedPtr.cpp

#include <iostream>
#include <memory>
#include <thread>

using namespace std::literals::chrono_literals;

struct MyInt{
	int val{2017};
	~MyInt() {
		std::cout << “Good Bye” << ‘\n’;
	}
};

void showNumber(std::shared_ptr<MyInt> myInt) {
	std::cout << myInt->val << ‘\n’;
}

void threadCreator() {
	auto sharedPtr = std::make_shared<MyInt>();

	std::thread t1(showNumber, sharedPtr);
	std::thread t2(showNumber, sharedPtr);

	t1.detach();
	t2.detach();
}

int main(){
	std::cout << ‘\n’;

	threadCreator();

	std::this_thread::sleep_for(1s);
	
	std::cout << ‘\n’;
}
```

Эта программа отличается от предыдущей двумя важными деталями. Во-первых, вместо встроенного в язык типа указателя `MyInt*` в строке `auto sharedPtr = std::make_shared<MyInt>();` теперь используется библиотечный тип-обёртка [[shared_ptr|std::shared_ptr]]. Во-вторых, соответственно изменён тип функции `showNumber` (строка `void showNumber(std::shared_ptr<MyInt> myInt)`) – теперь она принимает аргумент типа умного указателя. Результат работы программы показан на рисунке. Из него видно, что деструктор для объекта вызывается – утечки памяти не происходит.

![[ParallelProg_232.png]]

### Сокращение времени блокировки

Пока какой-либо поток удерживает блокировку, никакой другой поток не может войти в критическую секцию, защищённую тем же мьютексом, и продолжить свою работу. Рассмотрим пример.
```c++
void setDataReadyBad(){
	std::lock_guard<std::mutex> lck(mutex_);
	mySharedWork = {1, 0, 3};
	dataReady = true;
	std::cout << “Data prepared” << ‘\n’;
	condVar.notify_one();
} // разблокировка

void setDataReadyGood(){
	mySharedWork = {1, 0, 3};
	{
		std::lock_guard<std::mutex> lck(mutex_);
		dataReady = true;
	} // разблокировка
	
	std::cout << “Data prepared” << ‘\n’;
	condVar.notify_one();
}
```

Функции `setDataReadyBad` и `setDataReadyGood` разными способами делают одно и то же – оповещают переменную условия о готовности некоторых данных. Переменная `dataReady` нужна для предотвращения [[variable conditions#Утерянные и ложные пробуждения|ложных и потерянных пробуждений]]. Поскольку эта переменная имеет неатомарный тип, доступ к ней необходимо синхронизировать – для этого используется блокировщик `lck`. Для того чтобы удерживать блокировку как можно меньшее время, в функции `setDataReadyGood` сделан внутренний блок, при выходе из которого блокировка снимается, и остальные действия, не связанные с переменной `dataReady`, выполняются уже за пределами блокировки.

### Обёртывание мьютекса в блокировщик

Не следует использовать мьютекс сам по себе, без обёртывания его в объект-блокировщик. Рассмотрим фрагмент кода.

```c++
std::mutex m;
m.lock();
// критическая секция
m.unlock();
```

Что-то неожиданное может произойти в критической секции или программист забудет вставить в конце вызов функции `unlock` – итог один. Мьютекс останется запертым, и другие потоки будут заблокированы, что может привести к мёртвой блокировке всей системы.

Благодаря блокировщикам, которые автоматизируют управление мьютексом, риск попадания в мёртвую блокировку значительно уменьшается. В соответствии с идиомой RAII блокировщик захватывает мьютекс в конструкторе и освобождает в деструкторе. Тогда показанный выше фрагмент кода принимает следующий вид.

```c++
std::mutex m;
...

{
	std::lock_guard<std::mutex> lockGuard(m);
	// критическая секция
} // освободить мьютекс
```

Дополнительный блок, ограниченный фигурными скобками, гарантирует автоматическое уничтожение локального объекта и, следовательно, освобождение мьютекса.

### Предпочтительный захват одного мьютекса

Логику программы следует продумывать таким образом, чтобы всякий раз требовался захват лишь одного мьютекса. Хотя, конечно, на практике бывают задачи, требующие одновременного захвата нескольких мьютексов, в этом случае заметно возрастает риск мёртвых блокировок, о чём пойдёт речь в одном из следующих разделов.

### Необходимость давать блокировщикам имена

Если объявить безымянный объект-блокировщик (например, типа [[lock#Тип std lock_guard|std::lock_guard]]), как в следующем примере, он уничтожится немедленно после создания:
```c++
std::mutex m;
...
{
	std::lock_guard<std::mutex>{m};
	// критическая секция
}
```

На первый взгляд, этот код выглядит вполне невинно, однако блокировщик уничтожается сразу после создания. Следовательно, критическая секция выполняется далее без всякой синхронизации. Напомним, что привязка времени жизни объекта к блоку кода, ограниченному фигурными скобками, составляет общепринятый приём программирования на языке C++, известный как идиома RAII. В частности, блокировщик должен захватывать мьютекс в конструкторе и освобождать в деструкторе. Следующий развёрнутый пример иллюстрирует странное поведение идиомы RAII, если объекту-обёртке не дать имени.

**Ошибочная реализация идиомы RAII с безымянным блокировщиком:**
```c++
// myGuard.cpp

#include <mutex>
#include <iostream>

template <typename T>
class MyGuard {
		T& myMutex;
	
	public:
		MyGuard(T& m):myMutex(m) {
			myMutex.lock();
			std::cout << “lock” << std::endl;
		}

		~MyGuard() {
			myMutex.unlock();
			std::cout << “unlock” << std::endl;
		}
};

int main() {
	std::cout << std::endl;

	std::mutex m;
	MyGuard<std::mutex> {m};                           // (1)
	std::cout << “CRITICAL SECTION” << std::endl;      // (2)

	std::cout << std::endl;
}                                                      // (3)
```

Конструктор и деструктор класса `MyGuard` вызывают функции `lock` и `unlock` мьютекса. Однако, поскольку объекту этого класса не дано имя, этот объект – временный, и его деструктор вызывается сразу после конструктора, в строке `MyGuard<std::mutex> {m};`, а не при выходе из блока. Следовательно, критическая секция в строке `std::cout << “CRITICAL SECTION” << std::endl;` выполняется без синхронизации. Запустив программу, можно убедиться, что разблокировка мьютекса происходит раньше, чем начинает выполняться критическая секция.

![[ParallelProg_233.png]]

### Атомарный захват нескольких мьютексов

Если потоку необходимо захватить более одного мьютекса, программисту нужно соблюдать крайнюю осторожность, чтобы во всех местах они захватывались в одном и том же порядке. В противном случае неудачное стечение обстоятельств при перемежающемся выполнении потоков может спровоцировать мёртвую блокировку. Рассмотрим пример.
```c++
void deadLock(CriticalData& a, CriticalData& b){
	std::lock_guard<std::mutex> guard1(a.mut);
	// через некоторое время

	std::lock_guard<std::mutex> guard2(b.mut);
	// обработка объектов a и b
}

...

std::thread t1([&]{deadLock(c1, c2);});
std::thread t2([&]{deadLock(c2, c1);});
...
```

Каждому из потоков `t1` и `t2` нужны для работы два находящихся в общем доступе объекта типа `CriticalData`. При этом объект типа `CriticalData` содержит собственный мьютекс, который должен использоваться для синхронизации доступа к этому объекту. К сожалению, двум потокам, выполняющим функцию `deadLock`, эти объекты передаются в различном порядке. Теперь программа находится в состоянии гонки. Если поток `t1` успевает захватить первый мьютекс, но не второй, а поток `t2` тем временем успевает захватить свой первый мьютекс, потоки до бесконечности блокируют друг друга, потому что первый мьютекс второго потока – это второй мьютекс первого потока, и наоборот.

К счастью, в стандартной библиотеке есть функция [[lock#Функция std lock|std::lock]] и класс [[lock#Тип std unique_lock|std::unique_lock]], который поддерживает отложенный захват. Показанный выше пример приобретает следующий вид:
```c++
void deadLock(CriticalData& a, CriticalData& b){
	unique_lock<mutex> guard1(a.mut, defer_lock);
	
	// через некоторое время
	unique_lock<mutex> guard2(b.mut, defer_lock);

	std::lock(guard1, guard2);
	// обработка объектов a и b
}
...

	std::thread t1([&]{deadLock(c1, c2);});
	std::thread t2([&]{deadLock(c2, c1);});
	
...
```

В стандарте C++17 появляется новый вид блокировщика, тип [[lock#Тип std scoped_lock|std::scoped_lock]], позволяющий блокировать произвольное число мьютексов атомарным образом. Теперь код становится ещё более очевидным.
```c++
void deadLock(CriticalData& a, CriticalData& b){
	unique_lock<mutex> guard1(a.mut, defer_lock);

	std::scoped_lock(a.mut, b.mut);
	// обработка объектов a и b
}
...

	std::thread t1([&]{deadLock(c1, c2);});
	std::thread t2([&]{deadLock(c2, c1);});

...
```

### Не вызывать неизвестный код под блокировкой

Вызов не вызывающей доверия функции `unknownFunction` из критической секции – лучший способ получить неопределённое поведение.
```c++
std::mutex m;
{
	std::lock_guard<std::mutex> lockGuard(m);
	sharedVariable= unknownFunction();
}
```

Можно лишь строить предположения о том, что делает вызванная функция.
* Если она пытается захватить мьютекс `m`, получится неопределённое поведение (чаще всего на практике оно превратится в мёртвую блокировку).
* Если эта функция запускает новый поток, который, в свою очередь, пытается захватить мьютекс `m`, и ждёт его завершения – результатом становится мёртвая блокировка.
* Если функция захватывает другой мьютекс `m2`, возможна мёртвая блокировка, поскольку мьютексы `m` и `m2` захватываются неатомарным образом.
* Даже если вызываемая функция не пытается прямо или косвенно захватить мьютекс `m` и программа кажется безопасной, безопасность эта лишь кажущаяся. Другой программист может внести в функцию изменение или подключить новую версию библиотеки, в которой она определена. После этого можно делать ставки, какая из перечисленных здесь неприятностей случится первой.
* Функция может работать корректно, но медленно – в этом случае страдает производительность всей системы, поскольку вызов функции не позволяет освободить мьютекс.

Здесь можно воспользоваться локальной переменной, как показано ниже.
```c++
std::mutex m,
auto tempVar = unknownFunction();
{
	std::lock_guard<std::mutex> lockGuard(m);
	sharedVariable = tempVar;
}
```

В самом деле, этот обходной манёвр устраняет все проблемы. Переменная `tempVar` локальна, и поэтому не может стать жертвой гонки данных. Функцию `unknownFunction` теперь можно вызывать без какой-либо синхронизации. Наконец, время удержания блокировки сокращено до минимума: под блокировкой выполняется лишь присваивание значения из локальной переменной `tempVar` в общедоступную переменную `sharedVariable`.

## Переменные условия

Идея синхронизации потоков посредством взаимных оповещений довольно проста, однако реализация этой идеи через переменные условия может оказаться весьма сложной. Основная причина состоит в том, что переменная условия не обладает состоянием. Для переменных условия [[variable conditions#Утерянные и ложные пробуждения|характерны две проблемы]]:
* если переменная условия получает оповещение, оно может оказаться адресованным другой переменной условия – эта ситуация известна как ложное пробуждение;
* если переменная условия получает оповещение до того, как поток начинает ожидать оповещения через неё, это оповещение будет потеряно.

### Обязательное использование предиката

Использование переменной условия без предиката способно привести к ложному пробуждению, потере пробуждения и к состоянию гонок. Рассмотрим пример.

**Использование переменной условия без предиката:**
```c++
// conditionVariableLostWakeup.cpp

#include <condition_variable>
#include <mutex>
#include <thread>

std::mutex mutex_;
std::condition_variable condVar;

void waitingForWork(){
	std::unique_lock<std::mutex> lck(mutex_);
	condVar.wait(lck);

	// обработка
}

void setDataReady(){
	condVar.notify_one();
}

int main(){
	std::thread t1(setDataReady);
	std::thread t2(waitingForWork);

	t1.join();
	t2.join();
}
```

Если поток `t1` запускается раньше, чем поток `t2`, программа попадает в мёртвую блокировку. В самом деле, поток `t1` посылает своё оповещение до того, как поток `t2` становится готов его принять. Оповещение оказывается утерянным. Вероятность такого сценария довольно высока, так как поток `t1` создается первым и выполняет меньше действий.

Чтобы устранить эту проблему, достаточно лишь добавить логическую переменную `dataReady`. Она также защищает от ложного пробуждения, поскольку позволяет ожидающему потоку убедиться в том, что ожидаемое событие действительно произошло. Исправленный код показан ниже.

**Использование переменной условия с предикатом:**
```c++
// conditioVarialbleLostWakeupSolved.cpp

#include <condition_variable>
#include <mutex>
#include <thread>

std::mutex mutex_;
std::condition_variable condVar;

bool dataReady{false};

void waitingForWork(){
	std::unique_lock<std::mutex> lck(mutex_);
	condVar.wait(lck, []{ return dataReady; });
	
	// do the work
}

void setDataReady(){
	{
		std::lock_guard<std::mutex> lck(mutex_);
		dataReady = true;
	}
	condVar.notify_one();
}

int main(){
	std::thread t1(waitingForWork);
	std::thread t2(setDataReady);

	t1.join();
	t2.join();
}
```

### Замена переменных условия обещаниями и фьючерсами

Для однократных оповещений обещания и фьючерсы могут оказаться лучшим решением, чем переменные условия. Логику работы предыдущей программы можно реализовать следующим образом.

**Оповещение через обещание и фьючерс:**
```c++
// notificationWithPromiseAndFuture.cpp

#include <future>
#include <utility>

void waitingForWork(std::future<void>&& fut) {
	fut.wait();
	// do the work
}

void setDataReady(std::promise<void>&& prom) {
	prom.set_value();
}

int main() {
	std::promise<void> sendReady;
	auto fut = sendReady.get_future();

	std::thread t1(waitingForWork, std::move(fut));
	std::thread t2(setDataReady, std::move(sendReady));

	t1.join();
	t2.join();
}
```

Здесь количество текста, необходимое для того, чтобы выразить логику функционирования программы, сведено к абсолютному минимуму. Обещание `prom` путём вызова функции-члена `set_value` посылает оповещение фьючерсу `fut`, который ожидает на функции `wait`. В этой реализации не нужны ни мьютексы, ни блокировщики, так как в ней нет критических секций. Поскольку ложных и утерянных пробуждений здесь быть не может, не нужен также и предикат.

Однако если логика работы программы требует многократных оповещений, применить пару «обещание–фьючерс», увы, не удастся.

## Обещания и фьючерсы

Обещания и фьючерсы часто представляют собой простую и удобную в использовании замену потокам и переменным условия.

### Предпочтительность асинхронных заданий

Всегда, когда есть такая возможность, для создания асинхронного задания следует пользоваться функцией [[async#std async|std::async]]. Например:
```c++
auto fut = std::async([]{ return 2000 + 11; });

// some time passes

std::cout << “fut.get(): “ << fut.get() << ‘\n’;
```

Вызов функции [[async#std async|std::async]] как бы говорит системе: «Выполни это задание», и при этом не имеет значения, будет оно выполнено немедленно или позднее, будет оно выполняться в отдельном потоке, в пуле потоков или в том же потоке, который запрашивает это задание, и даже – выполнится оно на центральном процессоре или на графическом. Клиентский код заинтересован лишь в том, чтобы однажды в будущем забрать результат выполнения этого задания с помощью функции `get`.

С концептуальной точки зрения управление потоками становится для асинхронного задания лишь деталью реализации. Программист только указывает, что должно быть сделано, а не как это должно делаться.

