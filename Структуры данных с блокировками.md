
[[#Структуры данных с блокировками|Структуры данных с блокировками]] 12 
1. [[#Общие соображения|Общие соображения]] 12.1
	1. [[#Стратегии блокировки|Стратегии блокировки]] 12.1.1
	2. [[#Гранулярность интерфейса|Гранулярность интерфейса]] 12.1.2
	3. [[#Типовые сценарии использования|Типовые сценарии использования]] 12.1.3
		1. [[#Производительность в ОС Linux|Производительность в ОС Linux]] 12.1.3.1
			1. [[#Исключительная блокировка|Исключительная блокировка]] 12.1.3.1.1
			2. [[#Блокировка на чтение и запись|Блокировка на чтение и запись]] 12.1.3.1.2
		2. [[#Производительность в ОС Windows|Производительность в ОС Windows]] 12.1.3.2
			1. [[#Исключительная блокировка|Исключительная блокировка]] 12.1.3.2.1
			2. [[#Блокировка на чтение и запись|Блокировка на чтение и запись]] 12.1.3.2.2
	4. [[#Избегание прорех|Избегание прорех]] 12.1.4
	5. [[#Конкуренция потоков|Конкуренция потоков]] 12.1.5
		1. [[#Суммирование в один поток без синхронизации|Суммирование в один поток без синхронизации]] 12.1.5.1
		2. [[#Суммирование в один поток с синхронизацией|Суммирование в один поток с синхронизацией]] 12.1.5.2
		3. [[#Анализ результатов измерений|Анализ результатов измерений]] 12.1.5.3
	6. [[#Масштабируемость|Масштабируемость]] 12.1.6
	7. [[#Инварианты|Инварианты]] 12.1.7

# Структуры данных с блокировками

## Общие соображения

Реализация потокобезопасных структур данных – особенная область программирования. Прежде чем погружаться в подробный разбор её специфических трудностей, дадим общую картину в виде списка вопросов, на которые нужно найти ответы при проектировании.

> **Стратегия блокировки.** Должна структура данных блокироваться крупными или мелкими частями? Блокировка структуры целиком проще в реализации, но усиливает конкуренцию потоков.

> **Гранулярность интерфейса.** Чем обширнее интерфейс потокобезопасной структуры данных, тем сложнее становится рассуждать о её использовании из нескольких потоков.

> **Типовые сценарии использования.** Если, например, разрабатываемая структура данных будет преимущественно использоваться для чтения, не стоит оптимизировать её для записи.

> **Избегание прорех.** Нельзя делать детали реализации доступными клиентскому коду.

> **Конкуренция потоков.** Насколько вероятны одновременные запросы к структуре данных из нескольких потоков?

> **Масштабируемость.** Как меняется быстродействие разрабатываемой структуры данных с ростом её размера или с ростом числа параллельных клиентов?

> **Инварианты.** Какие свойства и соотношения должны выполняться в структуре данных на всём протяжении её жизни?

> **Исключения.** Как структура данных должна вести себя с исключениями?

Конечно же, ответы на эти вопросы зависят друг от друга. Например, использование крупнозернистой стратегии блокировки упрощает рассуждения о гранулированном интерфейсе и об инвариантах. С другой стороны, это усиливает конкуренцию потоков и ухудшает масштабируемость.

### Стратегии блокировки

Какую стратегию блокировки должны поддерживать структуры данных: крупнозернистую или мелкозернистую? Прежде всего уточним, что имеется в виду под этими названиями. Крупнозернистая блокировка означает, что блокируется вся структура данных целиком, так что в любой момент времени её может использовать лишь один поток. [[Управление изменяемым состоянием#Потокобезопасный интерфейс|Шаблон проектирования «Потокобезопасный интерфейс»]], представляет собой типичный метод реализации крупнозернистой блокировки. Напомним принципы, лежащие в основе потокобезопасных интерфейсов.

> Все интерфейсные (т. е. с уровнем доступа `public`) функции-члены должны блокировать объект.

> Функции-члены, относящиеся к деталям реализации (с уровнем доступа `private` или `protected`), не должны захватывать блокировку.

> Интерфейсные функции-члены могут содержать вызовы лишь скрытых (`private` или `protected`), но не других интерфейсных функций-членов.

[[Управление изменяемым состоянием#Потокобезопасный интерфейс|Шаблон «Потокобезопасный интерфейс»]] обладает двумя привлекательными свойствами: все общедоступные функции-члены гарантированно потокобезопасны и гарантированно свободны от мёртвых блокировок. Потокобезопасность обеспечивается тем, что каждая общедоступная функция-член захватывает блокировку всего объекта. Отсутствие мёртвых блокировок следует из того, что каждая общедоступная функция, захватив блокировку, не может вызвать другую общедоступную функцию этого класса. Сказанное хорошо иллюстрирует следующий код.

**Потокобезопасный интерфейс:**
```c++
// threadSafeInterface.cpp

#include <iostream>
#include <mutex>
#include <thread>

class Critical {
	public:
		void interface1() const {
			std::lock_guard<std::mutex> lockGuard(mut);
			implementation1();
		}

		void interface2() {
			std::lock_guard<std::mutex> lockGuard(mut);
			implementation2();
			implementation3();
			implementation1();
		}

	private:
		void implementation1() const {
			std::cout << “implementation1: “
				<< std::this_thread::get_id() << std::endl;
		}

		void implementation2(){
			std::cout << “implementation2: “
				<< std::this_thread::get_id() << std::endl;
		}

		void implementation3(){
			std::cout << “implementation3: “
				<< std::this_thread::get_id() << std::endl;
		}
	mutable std::mutex mut;
};

int main(){
	std::cout << std::endl;

	std::thread t1([]{const Critical crit; crit.interface1();});
	std::thread t2([]{Critical crit; crit.interface2(); 
			crit.interface1();});

	Critical crit;
	crit.interface1();
	crit.interface2();
	
	t1.join();
	t2.join();
	
	std::cout << std::endl;
}
```

Потокобезопасные интерфейсы выглядят многообещающей идеей, но обладают и очевидными недостатками. Структура данных, построенная по принципу потокобезопасного интерфейса, представляет собой узкое место, поскольку в любой момент времени использовать её может лишь один поток. Это означает, что если в системе предполагается много параллельных потоков, работающих с одной структурой данных, стоит задуматься о более мелкозернистой стратегии блокировки. Например, вместо того чтобы защищать единой блокировкой весь односвязный список, можно блокировать доступ к отдельно взятым его элементам.

### Гранулярность интерфейса

Предположим, ставится цель реализовать класс `ThreadSafeQueue` – блокирующую обёртку над стандартным контейнером [[deque#std deque (Очередь)|std::deque]]. Следующий фрагмент кода должен дать общее представление об этом классе.
```c++
class ThreadSafeQueue{
...	
	public:
		bool empty() const;
		int pop();
...
	private:
		std::deque<int> data;
...
};
```

Для простоты здесь показаны лишь две функции-члена. Функция `empty` возвращает логическое значение, которое показывает, пуст ли контейнер, а функция `pop` извлекает из контейнера верхний элемент и возвращает его. Гранулярность этого интерфейса выбрана неправильно! Почему? Рассмотрим случай, когда два потока одновременно пытаются обратиться к одному контейнеру `ThreadSafeQueue`.­

```c++
std::shared_ptr<int> getHead() {
	if (!threadSafeQueue.empty()) {
		auto head = threadSafeQueue.pop();
		return head;
	}
	
	return std::shared_ptr<int>();
}
...

	std::thread t1([&]{ auto res = getHead();
		...
	});
	std::thread t2([&]{ auto res = getHead();
		...
	});
```

Этот код ведёт к состоянию гонки, результатом которого может стать неопределённое поведение. Между проверкой наличия элемента с помощью вызова функции `empty` и извлечением первого элемента очереди с помощью функции `pop` проходит некоторое время. В частности, операции, выполняемые двумя потоками, могут перемежаться следующим образом:

![[ParallelProg_234.png]]

Если в очереди `threadSafeQueue` находится только один элемент, вызов функции `pop` из потока `t2` попытается извлечь элемент из уже пустого контейнера. Хотя каждая функция-член, взятая по отдельности, потокобезопасна, их совместное применение обладает неопределённым поведением. Интерфейс класса возлагает ответственность за синхронизацию вызовов на клиента. Это далеко от идеала.

Изменение гранулярности функций-членов класса позволяет элегантно решить проблему. Довольно лишь объединить функции-члены `empty` и `pop` в одну.

```c++
class ThreadSafeQueue{
...
	public:
		std::shared_ptr<int> tryPop() {
			std::lock_guard<std::mutex> queLock(queMutex);
			
			if (!data.empty()){
				auto head = data.pop();
				return head;
			}
			
			return std::shared_ptr<int>();
		}
...
	private:
		std::deque<int> data;
		mutable std::lock_mutex queMutex;
...
};
```

### Типовые сценарии использования

Самый частый сценарий использования большинства структур данных – это доступ для чтения. [[lock#Блокировщик std shared_lock|Блокировка в режиме писателя и читателя]], позволяет оптимизировать структуру данных для чтения. Если для доступа к данным используется мьютекс типа [[mutex#std::shared_timed_mutex|std::shared_timed_mutex]], помещённый в блокировщик [[lock#Блокировщик std shared_lock|std::shared_lock]], имеет место режим совместного доступа, при котором несколько потоков могут читать общие данные; если же мьютекс поместить в блокировщик [[lock#Тип std lock_guard|std::lock_guard]] или [[lock#Тип std unique_lock|std::unique_lock]], получается исключительный режим, при котором лишь один поток имеет доступ к данным и может их безопасно модифицировать.

Телефонная книга – хороший пример структуры данных, которая используется для чтения значительно чаще, чем для записи, и, следовательно, является идеальным кандидатом для применения блокировки описанного типа. Начнём с исключительной блокировки на каждую операцию, чтобы измерить начальные показатели производительности. Для эксперимента использовалась книга на примерно 89 тысяч записей. Десять потоков читают из неё каждый по 89 тысяч записей в произвольном порядке, а один поток дописывает цифру 1 к каждому десятому номеру телефона. При этом все потоки, конечно же, работают параллельно.

На следующем рисунке показан фрагмент телефонной книги. Можно видеть, что пары имя–номер разделены между собой двоеточием, а в каждой паре номер отделён от имени запятой.

![[ParallelProg_235.png]]

Следующая программа читает данные из этого файла в структуру данных в оперативной памяти – ассоциативный массив.

**Телефонная книга с исключительной блокировкой:**
```c++
// exclusiveLockingTelebook.cpp

#include <chrono>
#include <fstream>
#include <future>
#include <iostream>
#include <mutex>
#include <random>
#include <regex>
#include <shared_mutex>
#include <sstream>
#include <string>
#include <unordered_map>
#include <vector>

using map = std::unordered_map<std::string, int>;

class TeleBook{
		mutable std::mutex teleBookMutex;
		mutable map teleBook;
		const std::string teleBookFile;
	public:
		TeleBook(const std::string& teleBookFile_):
		teleBookFile(teleBookFile_) {
			auto fileStream = openFile(teleBookFile);
			auto fileContent = readFile(std::move(fileStream));
			teleBook = createTeleBook(fileContent);
			std::cout<< “teleBook.size(): “<< teleBook.size()
					<< std::endl;
		}
		
		map get() const {
			std::lock_guard<std::mutex> lockTele(teleBookMutex);
			return teleBook;
		}
		
		int getNumber(const std::string& name) const {
			std::lock_guard<std::mutex> lockTele(teleBookMutex);
			return teleBook[name];
		}
		
		void setNewNumber(const std::string& name) {
			std::lock_guard<std::mutex> lockTele(teleBookMutex);
			teleBook[name]++;
		}
		
	private:
		std::ifstream openFile(const std::string& myFile) {
			std::ifstream file(myFile, std::ios::in);
			if ( !file ) {
				std::cerr << “Can’t open file “+ myFile + “!” 
					<< std::endl;
				exit(EXIT_FAILURE);
			}

			return file;
		}

		std::string readFile(std::ifstream file) {
			std::stringstream buffer;
			buffer << file.rdbuf();
			return buffer.str();
		}

		map createTeleBook(const std::string& fileCont) {
			map teleBook;
			std::regex regColon(“:”);
			
			std::sregex_token_iterator fileContIt(
				fileCont.begin(), fileCont.end(), regColon, -1);

			const std::sregex_token_iterator fileContEndIt;
			std::string entry;
			std::string key;
			int value;

			while (fileContIt != fileContEndIt) {
				entry = *fileContIt++;
				auto comma = entry.find(“,”);
				key = entry.substr(0, comma);
				value = std::stoi(entry.substr(
					comma + 1, entry.length() -1));
				teleBook[key] = value;
			}
			
			return teleBook;
		}
};

std::vector<std::string> getRandomNames(const map& teleBook) {
	std::vector<std::string> allNames;
	for (const auto& pair: teleBook) 
		allNames.push_back(pair.first);

	std::random_device randDev;
	std::mt19937 generator(randDev());
	
	std::shuffle(allNames.begin(), allNames.end(), generator);

	return allNames;
}

void getNumbers(
	const std::vector<std::string>& randomNames, TeleBook& teleBook)
{
	for (const auto& name: randomNames) 
		teleBook.getNumber(name);
}

int main() {
	std::cout << std::endl;
	
	// get the filename
	const std::string myFileName = “tele.txt”;
	TeleBook teleBook(myFileName);

	std::vector<std::string> allNames = getRandomNames(teleBook.get());
	std::vector<std::string> tenthOfAllNames(allNames.begin(),
			allNames.begin() + allNames.size() / 10);

	auto start = std::chrono::steady_clock::now();
		
		auto futReader0 = std::async(std::launch::async,
				[&]{ getNumbers(allNames, teleBook); });
		auto futReader1 = std::async(std::launch::async,
				[&]{ getNumbers(allNames, teleBook); });
		auto futReader2 = std::async(std::launch::async,
				[&]{ getNumbers(allNames, teleBook); });
		auto futReader3 = std::async(std::launch::async,
				[&]{ getNumbers(allNames, teleBook); });
		auto futReader4 = std::async(std::launch::async,
				[&]{ getNumbers(allNames, teleBook); });
		auto futReader5 = std::async(std::launch::async,
				[&]{ getNumbers(allNames, teleBook); });
		auto futReader6 = std::async(std::launch::async,
				[&]{ getNumbers(allNames, teleBook); });
		auto futReader7 = std::async(std::launch::async,
				[&]{ getNumbers(allNames, teleBook); });
		auto futReader8 = std::async(std::launch::async,
				[&]{ getNumbers(allNames, teleBook); });
		auto futReader9 = std::async(std::launch::async,
				[&]{ getNumbers(allNames, teleBook); });

		auto futWriter = std::async(std::launch::async,
			[&]{
				for (const auto& name: tenthOfAllNames)
					teleBook.setNewNumber(name);
		});

		futReader0.get(), futReader1.get(), futReader2.get(),
		futReader3.get(), futReader4.get(), futReader5.get(),
		futReader6.get(), futReader7.get(), futReader8.get(),
		futReader9.get(), futWriter.get();
	
	std::chrono::duration<double> duration =
				std::chrono::steady_clock::now() – start;

	std::cout<< “Process time: “<< duration.count()
				<< “ seconds”<< std::endl<< std::endl;
}
```

Начнём с конструктора класса `TeleBook` (строки `TeleBook(const std::string& teleBookFile_) { ... }`). Он открывает файл, читает его содержимое и создаёт телефонную книгу. Функция `getRandomNames` (строки `std::vector<std::string> getRandomNames(const map& teleBook) { ... }`) генерирует случайную перестановку имён из телефонной книги. Каждое десятое имя заносится в контейнер `tenthOfAllNames` – именно у этих абонентов будет изменён телефонный номер. Перейдём теперь к наиболее интересной части программы – строкам с `auto futReader0 = std::async( ...`. Каждый из десяти фьючерсов `futReader0` – `futReader9` запускается в отдельном потоке. Каждый из них читает данные из телефонной книги в случайном порядке посредством функции `getNumbers`. Тем временем ещё один фьючерс `futWriter` выполняет в своём потоке лямбда-функцию. Когда все фьючерсы завершают свою работу, строка `std::cout<< “Process time: “` печатает общее время обработки. Остаётся подчеркнуть, что все функции из интерфейса класса `TeleBook` (функции `get`, `getNumber` и `setNewNumber`) используют для синхронизации общий мьютекс `teleBookMutex` (строка `mutable std::mutex teleBookMutex;`) типа [[mutex|std::mutex]]. Этот мьютекс объявлен с ключевым словом [[mutable|mutable]], и, следовательно, его состояние можно менять в константных функциях-членах.

Теперь перейдём к оптимизации. Функции-члены `get` (строки `map get() const { ... }`) и `getNumber` (строки `int getNumber(const std::string& name) const { ... }`) не меняют состояние телефонной книги и, следовательно, могут пользоваться блокировкой в режиме чтения. Конечно же, эта оптимизация неприменима к функции `setNewNumber` (строки `void setNewNumber(const std::string& name) { ... }`). Для краткости ниже приведена только подвергшаяся оптимизации часть класса `TeleBook`, так как остальной текст программы не меняется.

**Телефонная книга с раздельной блокировкой на чтение и запись:**
```c++
// sharedLockingTelebook.cpp
...

class TeleBook{
		mutable std::shared_timed_mutex teleBookMutex;
		mutable map teleBook;
		const std::string teleBookFile;
	public:
		TeleBook(const std::string& teleBookFile_):
				teleBookFile(teleBookFile_) {
			auto fileStream = openFile(teleBookFile);
			auto fileContent = readFile(std::move(fileStream));
			teleBook = createTeleBook(fileContent);

			std::cout<< “teleBook.size(): “<< teleBook.size()
					<< std::endl;
		}

		map get() const {
			std::shared_lock<std::shared_timed_mutex>
					lockTele(teleBookMutex);

			return teleBook;
		}

		int getNumber(const std::string& name) const {
			std::shared_lock<std::shared_timed_mutex>
					lockTele(teleBookMutex);

			return teleBook[name];
		}

		void setNewNumber(const std::string& name) {
			std::lock_guard< std::shared_timed_mutex>
					lockTele(teleBookMutex);

			teleBook[name]++;
		}
};
...
```

Нет смысла сравнивать между собой производительность программы, собранной компилятором GCC под операционной системой Linux, с производительностью той же программы, собранной компилятором cl.exe под операционной системой Windows, если только они не запускаются на одинаковых компьютерах. Однако на каждой платформе можно сравнить производительность изначальной и оптимизированной версий программы. Результат оказывается весьма удивительным.

#### Производительность в ОС Linux

##### Исключительная блокировка

Результат запуска первоначальной версии программы показан на рисунке:
![[ParallelProg_236.png]]

##### Блокировка на чтение и запись

На следующем рисунке показан результат запуска усовершенствованной версии программы.
![[ParallelProg_237.png]]

Таким образом, блокировка в режимах чтения и записи даёт прирост производительности примерно в 15 %. Это меньше, чем можно было ожидать, поскольку операции чтения и записи соотносятся как 100 к 1.

#### Производительность в ОС Windows

##### Исключительная блокировка

Результат работы неоптимизированной версии программы показан на рисунке.

![[ParallelProg_238.png]]

##### Блокировка на чтение и запись

Ниже показан результат работы программы с внесёнными изменениями.

![[ParallelProg_239.png]]

Полученные в ОС Windows показатели сильно удивляют, ведь оптимизированная программа работает вдвое медленнее, чем программа с исключительной блокировкой на каждую операцию. Возможно, дело в высоких накладных расходах на более сложный мьютекс, которые превышают затраты на полезную работу под блокировкой.

### Избегание прорех

Не следует показывать клиентам внутренние детали структур данных. Просачивание деталей реализации может произойти при передаче результатов функции по ссылке или указателю. Ещё один трудно поддающийся обнаружению путь к утечке деталей реализации открывается с возможностью передачи в структуру данных произвольного вызываемого объекта.

**Дыра в интерфейсе:**
```c++
// lockDouble.cpp

#include <future>
#include <iostream>
#include <mutex>

class LockDouble{
	public:
		double get() const {
			std::lock_guard<std::mutex> lockDoubGuard(lockDoubMutex);
			return lockDoub;
		}

		void set(double val) {
			std::lock_guard<std::mutex> lockDoubGuard(lockDoubMutex);
			lockDoub = val;
		}

		template <typename Func>
		void apply(Func func) {
			std::lock_guard<std::mutex> lockDoubGuard(lockDoubMutex);
			func(lockDoub);
		}

	private:
		double lockDoub{};

		mutable std::mutex lockDoubMutex;
};

int main() {
	LockDouble lck1;

	auto fut1 = std::async([&lck1]{ lck1.set(20.11); });
	auto fut2 = std::async(
				[&lck1]{ std::cout << lck1.get() << std::endl; });

	double* loophole = nullptr;
	lck1.apply([&loophole](double& d) mutable { loophole = &d; });
	
	*loophole = 11.22;

	auto fut3 = std::async(
				[&lck1]{ std::cout << lck1.get() << std::endl; });
}
```

Класс `LockDouble` обладает понятным интерфейсом. Всякое обращение к переменной-члену `lockDoub` защищено мьютексом `lockDoubMutex`, помещённым в блокировщик [[lock#Тип std lock_guard|std::lock_guard]]. Функция-член `get` возвращает копию завёрнутых в объект данных, а не ссылку на них. Если бы она возвращала ссылку на переменную `lockDoub`, клиент легко мог бы спровоцировать гонку данных, как показано ниже.

```c++
...
double& get() {
	std::lock_guard<std::mutex> lockDoubGuard(lockDoubMutex);
	return lockDoub;
}

...

LockDouble lck;
lck.set(22.11);

double& d = lck.get();
d = 11.22;
```

Конечно, проблема здесь состоит в том, что с помощью ссылки `d` клиент может изменить переменную-член `lockDoub`, доступ к которой должен быть синхронизирован мьютексом `lockDoubMutex`. Эту дыру в интерфейсе обнаружить довольно просто. Сложнее обстоит дело с другой.

Функция-член `apply` открывает дорогу бесконтрольному вмешательству клиента в детали реализации объекта. Так, в строке `lck1.apply([&loophole](double& d) mutable { loophole = &d; });` объект принимает в себя лямбда-функцию, которую он должен применить к своему внутреннему состоянию, но эта функция похищает и выдаёт наружу указатель на переменную-член. Оператор присваивания в следующей строке модифицирует эту переменную без синхронизации. Здесь со всей очевидностью имеет место гонка данных. На следующем рисунке показан результат несинхронизированного доступа к переменной `lockDoub`.

![[ParallelProg_240.png]]

Инструмент `ThreadSanitizer` показывает гонку данных в явном виде: диагностические сообщения приведены на следующем рисунке.

![[ParallelProg_241.png]]

### Конкуренция потоков

Как часто в разрабатываемую структуру данных поступают одновременные запросы от клиентов? Если конкуренция потоков незначительна, простейшие примитивы синхронизации наподобие мьютексов и блокировщиков оказываются достаточно быстрыми. В этом случае использование тонких и трудных для понимания механизмов, основанных на атомарных переменных, может оказаться чрезмерным. Прежде чем переходить к таким усложнённым решениям, стоит измерить производительность системы. Чтобы составить представление о величине накладных расходов на блокировку, проведём несложный эксперимент.

[[Вычисление суммы элементов вектора#Вычисление суммы элементов вектора|Этот эксперимент]]. Программа заполняет вектор миллионом случайных чисел от 1 до 10 с равномерным распределением, затем несколькими способами подсчитывает их сумму. Для целей этого раздела интересны два из них.

#### Суммирование в один поток без синхронизации

Приведём ещё раз простейшее, основанное на цикле решение задачи.

**Суммирование в цикле по диапазону:**
```c++
// calculateWithLoop.cpp

#include <chrono>
#include <iostream>
#include <random>
#include <vector>

constexpr long long size = 100000000;

int main(){
	std::cout << std::endl;

	std::vector<int> randValues;
	randValues.reserve(size);

	// random values
	std::random_device seed;
	std::mt19937 engine(seed());
	std::uniform_int_distribution<> uniformDist(1, 10);

	for (long long i = 0 ; i < size ; ++i)
		randValues.push_back(uniformDist(engine));
		
	const auto sta = std::chrono::steady_clock::now();

	unsigned long long sum = {};
	for (auto n: randValues) 
		sum += n;

	const std::chrono::duration<double> dur =
		std::chrono::steady_clock::now() – sta;

	std::cout << “Time for addition “ << dur.count()
		<< “ seconds” << std::endl;

	std::cout << “Result: “ << sum << std::endl;
	std::cout << std::endl;
}
```

Результат работы этой программы с показателем производительности в ОС Linux и Windows показан на следующих рисунках.

![[ParallelProg_242.png]]

![[ParallelProg_243.png]]

#### Суммирование в один поток с синхронизацией

Для сравнения рассмотрим работу такого же цикла по диапазону с единственным отличием – синхронизацией с помощью мьютекса. Ниже показана только отличающаяся часть кода.

```c++
// calculateWithLock.cpp
...
std::mutex myMutex;

for (auto i: randValues){
	std::lock_guard<std::mutex> myLockGuard(myMutex);
	sum += i;
}
```

Показатели производительности этой программы в двух ОС показаны на рисунках.

![[ParallelProg_244.png]]

![[ParallelProg_245.png]]

#### Анализ результатов измерений

Конечно, несинхронизированная программа работает в 50–150 раз быстрее, чем программа с блокировками. Казалось бы, числа говорят сами за себя и ясно свидетельствуют против стандартных блокировок. Однако следует учесть, что этот алгоритм захватывает мьютекс миллион раз, каждый раз выполняя под блокировкой одну очень быструю операцию. Если же захват блокировки требуется лишь изредка, стандартные примитивы могут оказаться наилучшим и достаточно быстрым решением.

### Масштабируемость

Как меняются показатели производительности структуры данных с ростом числа использующих её параллельных потоков? Как они меняются с ограничением объёма данных? На эти два вопроса стоит найти точный ответ. Идеал масштабируемости – линейный рост пропускной способности структуры данных с ростом числа клиентов.

Пусть, например, есть потокобезопасная очередь, способная в каждый момент времени обслуживать одного производителя или одного потребителя. Все прочие производители или потребители вынуждены ждать, пока не закончит работу предыдущий клиент. Это ограничение преодолевается очередью, способной работать со множеством производителей и потребителей одновременно. Этот второй сценарий будем для краткости называть сценарием `n×n` (где `n` может, в частном случае, равняться единице). Такой сценарий имеет место, когда производители обеспечивают всех потребителей, и наоборот, ведь в противном случае либо производителям, либо потребителям пришлось бы тратить время на ожидание, что противоречит масштабируемости.

Если потокобезопасная очередь ограничена в размере, от неё нельзя ожидать идеальной масштабируемости, так как при достижении предельного числа элементов в очереди система застопоривается. Введение буфера между производителями и потребителями помогает ослабить связь между ними, но не решает проблему полностью.

Разберём ответ на два поставленных вопроса в случае [[Шаблоны параллельной архитектуры#Шаблоны параллельной архитектуры|потокобезопасной очереди ThreadSafeQueue]].

**Объект-монитор:**
```c++
#include <condition_variable>
#include <functional>
#include <queue>
#include <iostream>
#include <mutex>
#include <random>
#include <thread>

template <typename T>
class Monitor {
	public:
		void lock() const {
			monitMutex.lock();
		}

		void unlock() const {
			monitMutex.unlock();
		}

		void notify_one() const noexcept {
			monitCond.notify_one();
		}

		void wait() const {
			std::unique_lock<std::recursive_mutex> monitLock(monitMutex);
			monitCond.wait(monitLock);
		}
	private:
		mutable std::recursive_mutex monitMutex;
		mutable std::condition_variable_any monitCond;
};

template <typename T>
class ThreadSafeQueue: public Monitor<ThreadSafeQueue<T> > {
	public:
		void add(T val) {
			derived.lock();
		
			myQueue.push(val);
			
			derived.unlock();
			derived.notify_one();
		}

		T get() {
			derived.lock();
			
			while (myQueue.empty()) 
				derived.wait();

			auto val = myQueue.front();
			myQueue.pop();

			derived.unlock();

			return val;
		}
	private:
		std::queue<T> myQueue;
		ThreadSafeQueue<T>& derived = 
					static_cast<ThreadSafeQueue<T>&>(*this);
};
```

Функция-член `add` (строка `void add(T val)`) добавляет элемент типа `T` к контейнеру [[queue#std queue (Очередь) C++11|std::queue]], а функция-член `get` (строка `T get()`) удаляет элемент из него. Класс `ThreadSafeQueue` воплощает шаблон «объект-монитор». Данный шаблон проектирования предписывает синхронизировать выполнение функций-членов объекта таким образом, чтобы не более одной интерфейсной функции выполнялось в любой момент времени. Когда производитель заканчивает добавление нового элемента в очередь, он оповещает одного потребителя посредством переменной условия (строка `mutable std::condition_variable_any monitCond;`). Рекурсивный мьютекс, объявленный в строке `mutable std::recursive_mutex monitMutex;`, защищает структуру данных от несогласованных модификаций. Этого описания должно быть достаточно, чтобы ответить на два поставленных вопроса (больше подробностей об этом [[шаблон Объект-монитор#Объект-монитор|шаблоне проектирования]]).
* Вполне очевидно, что потребитель может оказаться заблокированным в строке `while (myQueue.empty()) derived.wait();`, если очередь пуста.
* Ответ на второй вопрос ещё очевиднее, так как эта структура данных не ограничена в размере.

### Инварианты

Инвариант – это условие или соотношение, которое должно оставаться истинным во всё время существования некоторой структуры данных. Например, сумма кредитов и дебетов по всем счетам в любой момент времени должна быть равна нулю. Должна – но в приведённой ниже программе не равняется.
























