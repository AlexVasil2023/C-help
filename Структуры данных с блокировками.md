
[[#Структуры данных с блокировками|Структуры данных с блокировками]] 12 
1. [[#Общие соображения|Общие соображения]] 12.1
	1. [[#Стратегии блокировки|Стратегии блокировки]] 12.1.1
	2. [[#Гранулярность интерфейса|Гранулярность интерфейса]] 12.1.2
	3. [[#Типовые сценарии использования|Типовые сценарии использования]] 12.1.3

# Структуры данных с блокировками

## Общие соображения

Реализация потокобезопасных структур данных – особенная область программирования. Прежде чем погружаться в подробный разбор её специфических трудностей, дадим общую картину в виде списка вопросов, на которые нужно найти ответы при проектировании.

> **Стратегия блокировки.** Должна структура данных блокироваться крупными или мелкими частями? Блокировка структуры целиком проще в реализации, но усиливает конкуренцию потоков.

> **Гранулярность интерфейса.** Чем обширнее интерфейс потокобезопасной структуры данных, тем сложнее становится рассуждать о её использовании из нескольких потоков.

> **Типовые сценарии использования.** Если, например, разрабатываемая структура данных будет преимущественно использоваться для чтения, не стоит оптимизировать её для записи.

> **Избегание прорех.** Нельзя делать детали реализации доступными клиентскому коду.

> **Конкуренция потоков.** Насколько вероятны одновременные запросы к структуре данных из нескольких потоков?

> **Масштабируемость.** Как меняется быстродействие разрабатываемой структуры данных с ростом её размера или с ростом числа параллельных клиентов?

> **Инварианты.** Какие свойства и соотношения должны выполняться в структуре данных на всём протяжении её жизни?

> **Исключения.** Как структура данных должна вести себя с исключениями?

Конечно же, ответы на эти вопросы зависят друг от друга. Например, использование крупнозернистой стратегии блокировки упрощает рассуждения о гранулированном интерфейсе и об инвариантах. С другой стороны, это усиливает конкуренцию потоков и ухудшает масштабируемость.

### Стратегии блокировки

Какую стратегию блокировки должны поддерживать структуры данных: крупнозернистую или мелкозернистую? Прежде всего уточним, что имеется в виду под этими названиями. Крупнозернистая блокировка означает, что блокируется вся структура данных целиком, так что в любой момент времени её может использовать лишь один поток. [[Управление изменяемым состоянием#Потокобезопасный интерфейс|Шаблон проектирования «Потокобезопасный интерфейс»]], представляет собой типичный метод реализации крупнозернистой блокировки. Напомним принципы, лежащие в основе потокобезопасных интерфейсов.

> Все интерфейсные (т. е. с уровнем доступа `public`) функции-члены должны блокировать объект.

> Функции-члены, относящиеся к деталям реализации (с уровнем доступа `private` или `protected`), не должны захватывать блокировку.

> Интерфейсные функции-члены могут содержать вызовы лишь скрытых (`private` или `protected`), но не других интерфейсных функций-членов.

[[Управление изменяемым состоянием#Потокобезопасный интерфейс|Шаблон «Потокобезопасный интерфейс»]] обладает двумя привлекательными свойствами: все общедоступные функции-члены гарантированно потокобезопасны и гарантированно свободны от мёртвых блокировок. Потокобезопасность обеспечивается тем, что каждая общедоступная функция-член захватывает блокировку всего объекта. Отсутствие мёртвых блокировок следует из того, что каждая общедоступная функция, захватив блокировку, не может вызвать другую общедоступную функцию этого класса. Сказанное хорошо иллюстрирует следующий код.

**Потокобезопасный интерфейс:**
```c++
// threadSafeInterface.cpp

#include <iostream>
#include <mutex>
#include <thread>

class Critical {
	public:
		void interface1() const {
			std::lock_guard<std::mutex> lockGuard(mut);
			implementation1();
		}

		void interface2() {
			std::lock_guard<std::mutex> lockGuard(mut);
			implementation2();
			implementation3();
			implementation1();
		}

	private:
		void implementation1() const {
			std::cout << “implementation1: “
				<< std::this_thread::get_id() << std::endl;
		}

		void implementation2(){
			std::cout << “implementation2: “
				<< std::this_thread::get_id() << std::endl;
		}

		void implementation3(){
			std::cout << “implementation3: “
				<< std::this_thread::get_id() << std::endl;
		}
	mutable std::mutex mut;
};

int main(){
	std::cout << std::endl;

	std::thread t1([]{const Critical crit; crit.interface1();});
	std::thread t2([]{Critical crit; crit.interface2(); 
			crit.interface1();});

	Critical crit;
	crit.interface1();
	crit.interface2();
	
	t1.join();
	t2.join();
	
	std::cout << std::endl;
}
```

Потокобезопасные интерфейсы выглядят многообещающей идеей, но обладают и очевидными недостатками. Структура данных, построенная по принципу потокобезопасного интерфейса, представляет собой узкое место, поскольку в любой момент времени использовать её может лишь один поток. Это означает, что если в системе предполагается много параллельных потоков, работающих с одной структурой данных, стоит задуматься о более мелкозернистой стратегии блокировки. Например, вместо того чтобы защищать единой блокировкой весь односвязный список, можно блокировать доступ к отдельно взятым его элементам.

### Гранулярность интерфейса

Предположим, ставится цель реализовать класс `ThreadSafeQueue` – блокирующую обёртку над стандартным контейнером [[deque#std deque (Очередь)|std::deque]]. Следующий фрагмент кода должен дать общее представление об этом классе.
```c++
class ThreadSafeQueue{
...	
	public:
		bool empty() const;
		int pop();
...
	private:
		std::deque<int> data;
...
};
```

Для простоты здесь показаны лишь две функции-члена. Функция `empty` возвращает логическое значение, которое показывает, пуст ли контейнер, а функция `pop` извлекает из контейнера верхний элемент и возвращает его. Гранулярность этого интерфейса выбрана неправильно! Почему? Рассмотрим случай, когда два потока одновременно пытаются обратиться к одному контейнеру `ThreadSafeQueue`.­

```c++
std::shared_ptr<int> getHead() {
	if (!threadSafeQueue.empty()) {
		auto head = threadSafeQueue.pop();
		return head;
	}
	
	return std::shared_ptr<int>();
}
...

	std::thread t1([&]{ auto res = getHead();
		...
	});
	std::thread t2([&]{ auto res = getHead();
		...
	});
```

Этот код ведёт к состоянию гонки, результатом которого может стать неопределённое поведение. Между проверкой наличия элемента с помощью вызова функции `empty` и извлечением первого элемента очереди с помощью функции `pop` проходит некоторое время. В частности, операции, выполняемые двумя потоками, могут перемежаться следующим образом:

![[ParallelProg_234.png]]

Если в очереди `threadSafeQueue` находится только один элемент, вызов функции `pop` из потока `t2` попытается извлечь элемент из уже пустого контейнера. Хотя каждая функция-член, взятая по отдельности, потокобезопасна, их совместное применение обладает неопределённым поведением. Интерфейс класса возлагает ответственность за синхронизацию вызовов на клиента. Это далеко от идеала.

Изменение гранулярности функций-членов класса позволяет элегантно решить проблему. Довольно лишь объединить функции-члены `empty` и `pop` в одну.

```c++
class ThreadSafeQueue{
...
	public:
		std::shared_ptr<int> tryPop() {
			std::lock_guard<std::mutex> queLock(queMutex);
			
			if (!data.empty()){
				auto head = data.pop();
				return head;
			}
			
			return std::shared_ptr<int>();
		}
...
	private:
		std::deque<int> data;
		mutable std::lock_mutex queMutex;
...
};
```

### Типовые сценарии использования




























