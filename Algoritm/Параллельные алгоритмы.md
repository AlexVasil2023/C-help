
1. [[#Параллельные алгоритмы C++17]]
2. [[#Введение в параллельные алгоритмы]]
3. [[#Параллельный transform std transform]]
4. [[#Как использовать параллельные алгоритмы]]
5. [[#Политики исполнения]]

# Параллельные алгоритмы C++17

В С++17 появились параллельные алгоритмы, позволяющие увеличить производительность приложения. 

# Введение в параллельные алгоритмы


```c++
std::vector<int> longVector;

// Поиск элемента с использованием политики параллельного выполнения
auto result1 = std::find(std::execution::par, std::begin(longVector), std::end(longVector), 2);

// Сортировка элементов с использование политики последовательного выполнения
auto result2 = std::sort(std::execution::seq, std::begin(longVector), std::end(longVector));
```

В качестве быстрого примера вызовем `std::sort` параллельно:

```c++
std::sort(std::execution::par, myVec.begin(), myVec.end());       
// ^^^^^^^^^^^^^^^^^^^       
// политика выполнения
```

Обратите внимание, как просто добавить параметр параллельного выполнения в алгоритм! Но удастся ли добиться значительного улучшения производительности? Увеличит ли это скорость? Или есть случаи замедления?

# Параллельный [[transform|std::transform]]

В этой статье, я хочу обратить внимание на алгоритм [[transform|std::transform]], который потенциально может быть основой для других параллельных методов (наравне с [[transform|std::transform_reduce]], [[for_each|for_each]], [[scan|scan]], [[sort|sort]] ...).  
  
Наш тестовый код будет строиться по следующему шаблону:

```c++
std::transform(execution_policy,         // par, seq, par_unseq
			   inVec.begin(), inVec.end(),
			   outVec.begin(),                
			   ElementOperation);
```

Предположим, что у функции `ElementOperation` нет никаких методов синхронизации, в таком случае у кода есть потенциал параллельного выполнения или даже векторизации. Каждое вычисление элемента независимо, порядок не имеет значения, поэтому реализация может порождать несколько потоков (возможно в пуле потоков) для независимой обработки элементов.  
  
Я бы хотел поэкспериментировать со следующими вещами:

> - размер векторного поля — большое или маленькое;
> - простое преобразование, которое тратит большую часть времени на доступ к памяти;
> - больше арифметических (ALU) операций;
> - ALU в более реалистичном сценарии.





# Как использовать параллельные алгоритмы

Чтобы использовать библиотеку параллельных алгоритмов, следуйте данным шагам:

1. Найдите вызов алгоритма, который вы хотите оптимизировать с помощью распараллеливания. На эту роль хорошо подходят алгоритмы, которые делают больше чем `O(n)` работы, например, сортировка, и занимают значительное количество времени при профилировании приложения.

2. Убедитесь, что код, используемый в алгоритме, безопасен для распараллеливания.

3. Выберите политику параллельного исполнения (они будут описаны ниже).

4. Если вы ещё этого не сделали, добавьте строку `#include <execution>`, чтобы сделать доступными политики параллельного исполнения.

5. Добавьте одну из политик в качестве первого параметра вызова алгоритма для распараллеливания.

6. Протестируйте результат, чтобы убедиться, что новая версия работает лучше. Распараллеливание не всегда работает быстрее, особенно когда используются итераторы непроизвольного доступа, когда набор входных данных мал или когда дополнительное распараллеливание создаёт конфликт внешних ресурсов вроде диска.

Вот пример программы, которую мы хотим сделать быстрее. Она считает, сколько времени требуется для сортировки миллиона чисел:

```c++
// Компилировать с помощью: 
// debug: cl /EHsc /W4 /WX /std:c++latest /Fedebug /MDd .\program.cpp 
// release: cl /EHsc /W4 /WX /std:c++latest /Ferelease /MD /O2 .\program.cpp 

#include <stddef.h> 
#include <stdio.h> 
#include <algorithm> 
#include <chrono> 
#include <random> 
#include <ratio> 
#include <vector> 

using std::chrono::duration; 
using std::chrono::duration_cast; 
using std::chrono::high_resolution_clock; 
using std::milli; 
using std::random_device; 
using std::sort; 
using std::vector; 

const size_t testSize = 1'000'000; 
const int iterationCount = 5;

void print_results(const char *const tag, const vector<double>& sorted, 
				   high_resolution_clock::time_point startTime, 
				   high_resolution_clock::time_point endTime) { 
	
	printf("%s: Lowest: %g Highest: %g Time: %fms", 
			tag, 
			sorted.front(), 
			sorted.back(), 
			duration_cast<duration<double, milli>>
					(endTime - startTime).count()); 
}

int main() { 
	random_device rd; 
	
	// Генерируем случайные числа: 
	printf("Testing with %zu doubles...", testSize); 
	vector<double> doubles(testSize); 
	
	for (auto& d : doubles) { 
		d = static_cast<double>(rd()); 
	} 
	
	// Измеряем время, необходимое на их сортировку: 
	for (int i = 0; i < iterationCount; ++i) { 
		vector<double> sorted(doubles); 
		
		const auto startTime = high_resolution_clock::now();
		sort(sorted.begin(), sorted.end()); 
		const auto endTime = high_resolution_clock::now();
		print_results("Serial", sorted, startTime, endTime); 
	} 
}
```

Параллельные алгоритмы зависят от доступного параллелизма оборудования, поэтому убедитесь, что вы проводите тесты на железе, производительность которого вам важна. Вам не нужно много ядер, чтобы показать прогресс, к тому же многие из алгоритмов построены по принципу «разделяй и властвуй», и поэтому не будут идеально ускоряться соответственно количеству потоков; но больше — всё равно лучше. В этом примере тестирование проводилось на системе с Intel 7980XE с 18 ядрами и 36 потоками. В этом тесте отладочная и релизная сборки программы показали следующий результат:

```
.\debug.exe 
Testing with 1000000 doubles... 
Serial: Lowest: 1349 Highest: 4.29497e+09 Time: 310.176500ms 
Serial: Lowest: 1349 Highest: 4.29497e+09 Time: 304.714800ms 
Serial: Lowest: 1349 Highest: 4.29497e+09 Time: 310.345800ms 
Serial: Lowest: 1349 Highest: 4.29497e+09 Time: 303.302200ms 
Serial: Lowest: 1349 Highest: 4.29497e+09 Time: 290.694300ms 

C:\Users\bion\Desktop>.\release.exe 
Testing with 1000000 doubles... 
Serial: Lowest: 2173 Highest: 4.29497e+09 Time: 74.590400ms 
Serial: Lowest: 2173 Highest: 4.29497e+09 Time: 75.703500ms 
Serial: Lowest: 2173 Highest: 4.29497e+09 Time: 87.839700ms 
Serial: Lowest: 2173 Highest: 4.29497e+09 Time: 73.822300ms 
Serial: Lowest: 2173 Highest: 4.29497e+09 Time: 73.757400ms
```

Теперь нам нужно убедиться, что вызов сортировки безопасен для распараллеливания. Алгоритмы безопасны для распараллеливания, если «функции доступа к элементу» — операции итерирования, предикаты и всё остальное, что вы можете попросить алгоритм сделать, — следуют обычному правилу для состояния гонки: «любое количество операций чтения или максимум одна операции записи». Более того, они не должны выбрасывать исключения (или выбрасывать достаточно редко, чтобы завершение программы не имело негативных последствий).

# Политики исполнения

Теперь нужно выбрать политику исполнения. На данный момент стандарт включает в себя параллельную политику, обозначаемую как `std::execution::par`, и параллельную непоследовательную политику, обозначаемую как `std::execution::par_unseq`. В дополнение к требованиям первой, вторая требует, чтобы функции доступа к элементам допускали гарантии прогресса слабее параллельного выполнения. Это значит, что они не должны устанавливать блокировку или делать ещё что-то, что потребует от потоков конкурентного исполнения. Например, если алгоритм работает на графическом процессоре и пытается установить спинлок, поток, который держит этот спинлок, может помешать выполнению других потоков, и спинлок не будет снят. Больше о требованиях можно прочитать в разделах `algorithms.parallel.defns` и `algorithms.parallel.exec` стандарта C++. Если у вас есть сомнения, используйте параллельную политику. В этом примере мы используем оператор «меньше» для типа `double`, который не устанавливает никаких блокировок, и тип итератора, предоставленный стандартной библиотекой, поэтому мы можем использовать параллельную непоследовательную политику.

Обратите внимание, Visual C++ реализует параллельные и параллельные непоследовательные политики одинаковым образом, поэтому не стоит ожидать лучшей производительности при использовании `par_unseq`, хотя могут существовать реализации, которые однажды смогут использовать эту дополнительную свободу.

В пример сортировки чисел мы теперь можем добавить `#include <execution>`. Так как мы используем параллельную непоследовательную политику, мы добавляем `std::execution::par_unseq` в вызов алгоритма (при использовании параллельной политики нужно было бы использовать `std::execution::par`). Теперь `for`-цикл в `main()` выглядит так:

```c++
for (int i = 0; i < iterationCount; ++i) { 
	vector<double> sorted(doubles); 
	
	const auto startTime = high_resolution_clock::now(); 
	// Тот же вызов sort, что и выше, только с par_unseq: 
	sort(std::execution::par_unseq, sorted.begin(), sorted.end()); 
	const auto endTime = high_resolution_clock::now(); 
	// Обратите внимание, что в выводе это параллельные результаты 
	print_results("Parallel", sorted, startTime, endTime); }
```

Тестируем:

```
.\debug.exe 
Testing with 1000000 doubles... 
Parallel: Lowest: 6642 Highest: 4.29496e+09 Time: 54.815300ms 
Parallel: Lowest: 6642 Highest: 4.29496e+09 Time: 49.613700ms 
Parallel: Lowest: 6642 Highest: 4.29496e+09 Time: 49.504200ms 
Parallel: Lowest: 6642 Highest: 4.29496e+09 Time: 49.194200ms 
Parallel: Lowest: 6642 Highest: 4.29496e+09 Time: 49.162200ms 

.\release.exe 
Testing with 1000000 doubles... 
Parallel: Lowest: 18889 Highest: 4.29496e+09 Time: 20.971100ms 
Parallel: Lowest: 18889 Highest: 4.29496e+09 Time: 17.510700ms 
Parallel: Lowest: 18889 Highest: 4.29496e+09 Time: 17.823800ms 
Parallel: Lowest: 18889 Highest: 4.29496e+09 Time: 20.230400ms 
Parallel: Lowest: 18889 Highest: 4.29496e+09 Time: 19.461900ms
```

Для этих входных данных программа сработала быстрее. Как вы будете тестировать программу зависит от выбранных вами критериев. Распараллеливание добавляет некоторую нагрузку и будет работать медленнее, чем последовательная версия, для малого числа `N` в зависимости от памяти и эффектов кеша, а также других факторов, специфичных для конкретной нагрузки. Если в этом примере установить значение `N` равным 1000, параллельная и последовательная версии будут работать примерно с одной скоростью, а если изменить значение на 100, то последовательная версия будет в 10 раз быстрее. Распараллеливание может оказать положительный эффект, но важно понимать, где его применять.







